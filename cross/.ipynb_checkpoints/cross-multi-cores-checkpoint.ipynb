{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "\n",
    "from envs.test_env_v2 import TestEnv_v2\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 64\n",
    "PERCENTILE = 70\n",
    "LEARNING_RATE = 0.0005\n",
    "REUSE_TIMES = 6\n",
    "GAMMA = 1.001\n",
    "\n",
    "USE_CORES = 8\n",
    "\n",
    "INIT_ROUNDS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, obs_size, hidden_size, n_actions):\n",
    "        super(Net, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_size[1], hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, int(hidden_size/2)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.out = nn.Linear(obs_size[0] * int(hidden_size/2), n_actions) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = x.view(x.size(0), -1)   # to (batch_size, obs_size[0] * hidden_size/2)\n",
    "        output = self.out(x)\n",
    "        return output\n",
    "\n",
    "Episode = namedtuple('Episode', field_names=['reward', 'steps', 'info'])\n",
    "EpisodeStep = namedtuple('EpisodeStep', field_names=['observation', 'action'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "global total_batch\n",
    "def produce_batches(env_input, net, batch_size):\n",
    "    env = copy.deepcopy(env_input)\n",
    "    np.random.seed()\n",
    "    batch = []\n",
    "    episode_reward = 0.0\n",
    "    episode_steps = []\n",
    "    obs = env.reset()\n",
    "    sm = nn.Softmax(dim=1)\n",
    "    times = 0\n",
    "    \n",
    "    while True:\n",
    "        obs_v = torch.FloatTensor([obs]).cuda()\n",
    "        act_probs_v = sm(net(obs_v))\n",
    "        act_probs = act_probs_v.cpu().data.numpy()[0]\n",
    "        action = np.random.choice(len(act_probs), p=act_probs)\n",
    "        next_obs, reward, is_done, ext_info = env.step(action)\n",
    "        episode_reward += reward * (GAMMA ** len(episode_steps))\n",
    "        episode_steps.append(EpisodeStep(observation=obs, action=action))\n",
    "        if is_done or ext_info[3] > 10000:\n",
    "            batch.append(Episode(reward=episode_reward, steps=episode_steps, info=ext_info))\n",
    "            episode_reward = 0.0\n",
    "            episode_steps = []\n",
    "            next_obs = env.reset()\n",
    "\n",
    "#             print(\"%d\"% (times%8), end='', flush=True)\n",
    "#             times += 1\n",
    "#             if times%8 == 0:\n",
    "#                 print(\"|\", end='')\n",
    "\n",
    "            if len(batch) == batch_size:\n",
    "#                 print(\" \")\n",
    "                times = 0\n",
    "                del obs_v, act_probs_v, act_probs, ext_info\n",
    "                return batch\n",
    "\n",
    "        obs = next_obs\n",
    "\n",
    "def collect_results(mini_batch):\n",
    "    total_batch.extend(mini_batch)\n",
    "\n",
    "def apply_async_with_callback(pool, core_num, env, net, batch_size):\n",
    "    core_thrd = []\n",
    "    for _ in range(core_num):\n",
    "        core_thrd.append(pool.apply_async(produce_batches, args=(env, net, int(batch_size/core_num)),\n",
    "                         callback=collect_results))\n",
    "    for i in range(core_num):\n",
    "        core_thrd[i].get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_batch(batch, percentile):\n",
    "    rewards = list(map(lambda s: s.reward, batch))\n",
    "    reward_bound = np.percentile(rewards, percentile)\n",
    "    reward_mean = float(np.mean(rewards))\n",
    "    infos = np.array(list(map(lambda s: s.info, batch)))\n",
    "    info_mean = np.mean(infos,axis=0)\n",
    "\n",
    "    train_obs = []\n",
    "    train_act = []\n",
    "    elite_batch = []\n",
    "    for example, discounted_reward in zip(batch, rewards):\n",
    "        if discounted_reward > reward_bound:\n",
    "            train_obs.extend(map(lambda step: step.observation, example.steps))\n",
    "            train_act.extend(map(lambda step: step.action, example.steps))\n",
    "            elite_batch.append(example)\n",
    "\n",
    "    return elite_batch, train_obs, train_act, reward_bound, reward_mean, info_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_init_batch(env,batch_size):\n",
    "    batch = []\n",
    "    episode_reward = 0.0\n",
    "    episode_steps = []\n",
    "    obs = env.reset()\n",
    "    r = 0\n",
    "    test_num = 0\n",
    "    times = 0\n",
    "    while True:\n",
    "        r = random.randint(0,99)\n",
    "        next_obs, reward, is_done,  ext_info = env.step(r)\n",
    "        episode_reward += reward * (GAMMA ** len(episode_steps))\n",
    "        episode_steps.append(EpisodeStep(observation=obs, action=r))\n",
    "        if is_done:\n",
    "            batch.append(Episode(reward=episode_reward, steps=episode_steps, info=ext_info))\n",
    "            episode_reward = 0.0\n",
    "            episode_steps = []\n",
    "            next_obs = env.reset()\n",
    "            if times%8 == 0:\n",
    "                print(\"|\", end='')\n",
    "            print(\"%d\"% (times%8), end='',flush=True)\n",
    "            times += 1\n",
    "            if len(batch) == batch_size:\n",
    "                print(\" \")\n",
    "                yield batch\n",
    "                batch = []\n",
    "                test_num +=1\n",
    "                times = 0\n",
    "                if test_num == INIT_ROUNDS:\n",
    "                    break\n",
    "        obs = next_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 4 GPUs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-4-0313bb701344>\", line 13, in produce_batches\n",
      "    obs_v = torch.FloatTensor([obs]).cuda()\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-4-0313bb701344>\", line 13, in produce_batches\n",
      "    obs_v = torch.FloatTensor([obs]).cuda()\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-4-0313bb701344>\", line 15, in produce_batches\n",
      "    act_probs = act_probs_v.cpu().data.numpy()[0]\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-4-0313bb701344>\", line 17, in produce_batches\n",
      "    next_obs, reward, is_done, ext_info = env.step(action)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-4-0313bb701344>\", line 13, in produce_batches\n",
      "    obs_v = torch.FloatTensor([obs]).cuda()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 138, in step\n",
      "    self._go_next_point(action)\n",
      "  File \"<ipython-input-4-0313bb701344>\", line 16, in produce_batches\n",
      "    action = np.random.choice(len(act_probs), p=act_probs)\n",
      "  File \"<ipython-input-4-0313bb701344>\", line 17, in produce_batches\n",
      "    next_obs, reward, is_done, ext_info = env.step(action)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"mtrand.pyx\", line 1133, in mtrand.RandomState.choice\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 213, in _go_next_point\n",
      "    self._get_state()\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 138, in step\n",
      "    self._go_next_point(action)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/numpy/core/numerictypes.py\", line 687, in issubdtype\n",
      "    def issubdtype(arg1, arg2):\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 194, in _go_next_point\n",
      "    self.round_state = copy.deepcopy(self.point_state)\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 230, in _get_state\n",
      "    self.state[i][j] = self.point_state[i].state()[j]\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/copy.py\", line 150, in deepcopy\n",
      "    y = copier(x, memo)\n",
      "  File \"<ipython-input-4-0313bb701344>\", line 14, in produce_batches\n",
      "    act_probs_v = sm(net(obs_v))\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 50, in state\n",
      "    return np.array(state)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/copy.py\", line 215, in _deepcopy_list\n",
      "    append(deepcopy(a, memo))\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/copy.py\", line 169, in deepcopy\n",
      "    rv = reductor(4)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 114, in forward\n",
      "    outputs = self.parallel_apply(replicas, inputs, kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 124, in parallel_apply\n",
      "    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\", line 59, in parallel_apply\n",
      "    _worker(0, modules[0], inputs[0], kwargs_tup[0], devices[0])\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\", line 41, in _worker\n",
      "    output = module(*input, **kwargs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-3-94f578790d8f>\", line 15, in forward\n",
      "    output = self.out(x)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 55, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/functional.py\", line 992, in linear\n",
      "    return torch.addmm(bias, input, weight.t())\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    env = TestEnv_v2()\n",
    "    # env = gym.wrappers.Monitor(env, directory=\"mon\", force=True)\n",
    "    # os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "    \n",
    "    \n",
    "    # print(device_lib.list_local_devices())\n",
    "    \n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    pool = mp.Pool(processes = USE_CORES)\n",
    "    \n",
    "    \n",
    "    obs_size = env.observation_size\n",
    "    n_actions = env.action_num\n",
    "\n",
    "    net = Net(obs_size, HIDDEN_SIZE, n_actions)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        net = nn.DataParallel(net)\n",
    "\n",
    "    net = net.cuda()\n",
    "    \n",
    "    objective = nn.CrossEntropyLoss().cuda()\n",
    "    optimizer = optim.Adam(params=net.parameters(), lr=LEARNING_RATE)\n",
    "    writer = SummaryWriter(comment=\"-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training!!!\n",
      "1: reward_mean=-12269.3, reward_bound=-9045.0, round_mean=32.3,     distance_mean=84.8, steps=1147 \n",
      "------ \n",
      "iter time: 51 s, localtime: Wed Nov 21 09:32:52 2018\n",
      "2: reward_mean=-10364.5, reward_bound=-7601.2, round_mean=32.2,     distance_mean=84.7, steps=1058 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 09:33:35 2018\n",
      "3: reward_mean=-10537.5, reward_bound=-7210.6, round_mean=32.3,     distance_mean=84.4, steps=1051 \n",
      "------ \n",
      "iter time: 32 s, localtime: Wed Nov 21 09:34:07 2018\n",
      "4: reward_mean=-11879.0, reward_bound=-6715.8, round_mean=32.6,     distance_mean=85.1, steps=1086 \n",
      "------ \n",
      "iter time: 33 s, localtime: Wed Nov 21 09:34:41 2018\n",
      "5: reward_mean=-10659.3, reward_bound=-6526.1, round_mean=31.2,     distance_mean=83.7, steps=1049 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 09:35:13 2018\n",
      "6: reward_mean=-10802.2, reward_bound=-6181.8, round_mean=31.7,     distance_mean=84.1, steps=1055 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 09:35:45 2018\n",
      "7: reward_mean=-10493.6, reward_bound=-5878.9, round_mean=31.2,     distance_mean=83.8, steps=1029 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 09:36:16 2018\n",
      "8: reward_mean=-10361.5, reward_bound=-5814.7, round_mean=31.5,     distance_mean=84.0, steps=1031 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 09:36:48 2018\n",
      "9: reward_mean=-10834.8, reward_bound=-5795.2, round_mean=31.1,     distance_mean=83.3, steps=1039 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 09:37:19 2018\n",
      "10: reward_mean=-10761.8, reward_bound=-5704.8, round_mean=31.6,     distance_mean=84.1, steps=1041 \n",
      "------ \n",
      "iter time: 33 s, localtime: Wed Nov 21 09:37:53 2018\n",
      "11: reward_mean=-9902.2, reward_bound=-5692.9, round_mean=30.8,     distance_mean=83.4, steps=1017 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 09:38:24 2018\n",
      "12: reward_mean=-9698.9, reward_bound=-5617.3, round_mean=31.4,     distance_mean=83.7, steps=994 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 09:38:55 2018\n",
      "13: reward_mean=-10116.6, reward_bound=-5580.3, round_mean=31.3,     distance_mean=83.8, steps=1019 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 09:39:26 2018\n",
      "14: reward_mean=-9936.6, reward_bound=-5659.7, round_mean=31.7,     distance_mean=84.2, steps=1011 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 09:39:57 2018\n",
      "15: reward_mean=-10810.2, reward_bound=-5597.5, round_mean=31.4,     distance_mean=83.5, steps=1046 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 09:40:28 2018\n",
      "16: reward_mean=-11144.7, reward_bound=-5490.8, round_mean=31.2,     distance_mean=83.7, steps=1047 \n",
      "------ \n",
      "iter time: 32 s, localtime: Wed Nov 21 09:41:01 2018\n",
      "17: reward_mean=-10229.1, reward_bound=-5436.5, round_mean=31.3,     distance_mean=83.7, steps=1017 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 09:41:32 2018\n",
      "18: reward_mean=-10926.1, reward_bound=-5751.1, round_mean=31.6,     distance_mean=83.6, steps=1058 \n",
      "------ \n",
      "iter time: 32 s, localtime: Wed Nov 21 09:42:05 2018\n",
      "19: reward_mean=-9444.0, reward_bound=-5296.6, round_mean=31.4,     distance_mean=83.6, steps=990 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 09:42:35 2018\n",
      "20: reward_mean=-9737.0, reward_bound=-5261.2, round_mean=32.0,     distance_mean=84.6, steps=999 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 09:43:06 2018\n",
      "21: reward_mean=-12726.2, reward_bound=-5217.8, round_mean=31.4,     distance_mean=84.0, steps=1046 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 09:43:38 2018\n",
      "22: reward_mean=-10407.4, reward_bound=-5258.7, round_mean=31.6,     distance_mean=83.9, steps=1017 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 09:44:10 2018\n",
      "23: reward_mean=-10355.6, reward_bound=-5247.0, round_mean=32.2,     distance_mean=84.4, steps=1028 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 09:44:41 2018\n",
      "24: reward_mean=-9754.8, reward_bound=-5191.6, round_mean=31.2,     distance_mean=83.5, steps=992 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 09:45:13 2018\n",
      "25: reward_mean=-10053.0, reward_bound=-5207.7, round_mean=31.0,     distance_mean=83.2, steps=1007 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 09:45:44 2018\n",
      "26: reward_mean=-9978.8, reward_bound=-5187.6, round_mean=31.4,     distance_mean=84.0, steps=1014 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 09:46:15 2018\n",
      "27: reward_mean=-9806.3, reward_bound=-5140.7, round_mean=31.4,     distance_mean=83.8, steps=989 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 09:46:45 2018\n",
      "28: reward_mean=-10287.3, reward_bound=-5146.9, round_mean=31.3,     distance_mean=83.6, steps=1020 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 09:47:17 2018\n",
      "29: reward_mean=-9946.7, reward_bound=-5018.9, round_mean=30.8,     distance_mean=83.6, steps=996 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 09:47:47 2018\n",
      "30: reward_mean=-9571.3, reward_bound=-5254.3, round_mean=31.4,     distance_mean=83.9, steps=995 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 09:48:17 2018\n",
      "31: reward_mean=-9577.9, reward_bound=-5107.0, round_mean=31.3,     distance_mean=83.5, steps=990 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 09:48:47 2018\n",
      "32: reward_mean=-10763.4, reward_bound=-5003.6, round_mean=31.2,     distance_mean=83.1, steps=1040 \n",
      "------ \n",
      "iter time: 32 s, localtime: Wed Nov 21 09:49:19 2018\n",
      "33: reward_mean=-9782.3, reward_bound=-5133.3, round_mean=31.5,     distance_mean=84.2, steps=1005 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 09:49:50 2018\n",
      "34: reward_mean=-10843.8, reward_bound=-4988.9, round_mean=31.2,     distance_mean=83.5, steps=1032 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 09:50:22 2018\n",
      "35: reward_mean=-9690.2, reward_bound=-4835.3, round_mean=31.7,     distance_mean=83.7, steps=995 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 09:50:53 2018\n",
      "36: reward_mean=-11532.1, reward_bound=-4941.3, round_mean=31.7,     distance_mean=84.2, steps=1032 \n",
      "------ \n",
      "iter time: 32 s, localtime: Wed Nov 21 09:51:25 2018\n",
      "37: reward_mean=-9965.9, reward_bound=-4808.2, round_mean=31.5,     distance_mean=83.7, steps=996 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 09:51:55 2018\n",
      "38: reward_mean=-9571.9, reward_bound=-4805.5, round_mean=31.4,     distance_mean=84.1, steps=991 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 09:52:26 2018\n",
      "39: reward_mean=-10490.2, reward_bound=-4876.8, round_mean=31.4,     distance_mean=83.6, steps=1022 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 09:52:57 2018\n",
      "40: reward_mean=-9786.4, reward_bound=-4764.8, round_mean=31.4,     distance_mean=83.4, steps=987 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 09:53:28 2018\n",
      "41: reward_mean=-9814.8, reward_bound=-4846.2, round_mean=31.1,     distance_mean=83.6, steps=991 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 09:53:59 2018\n",
      "42: reward_mean=-8838.1, reward_bound=-4737.8, round_mean=31.7,     distance_mean=84.4, steps=958 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 09:54:28 2018\n",
      "43: reward_mean=-10202.1, reward_bound=-5345.3, round_mean=31.4,     distance_mean=83.7, steps=1024 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 09:54:58 2018\n",
      "44: reward_mean=-10251.7, reward_bound=-4686.7, round_mean=31.3,     distance_mean=84.0, steps=1019 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 09:55:29 2018\n",
      "45: reward_mean=-11077.5, reward_bound=-4790.8, round_mean=31.2,     distance_mean=83.7, steps=1032 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 09:56:01 2018\n",
      "46: reward_mean=-9954.2, reward_bound=-4813.8, round_mean=31.8,     distance_mean=84.5, steps=1000 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 09:56:32 2018\n",
      "47: reward_mean=-10335.2, reward_bound=-4635.3, round_mean=31.7,     distance_mean=84.5, steps=1007 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 09:57:04 2018\n",
      "48: reward_mean=-9795.8, reward_bound=-5002.6, round_mean=31.5,     distance_mean=84.4, steps=994 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 09:57:34 2018\n",
      "49: reward_mean=-10061.4, reward_bound=-4573.8, round_mean=31.1,     distance_mean=83.6, steps=1002 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 09:58:04 2018\n",
      "50: reward_mean=-9530.0, reward_bound=-4541.2, round_mean=31.0,     distance_mean=83.4, steps=982 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 09:58:35 2018\n",
      "51: reward_mean=-9305.8, reward_bound=-4803.1, round_mean=31.4,     distance_mean=83.5, steps=969 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 09:59:05 2018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52: reward_mean=-9047.6, reward_bound=-4546.4, round_mean=31.7,     distance_mean=84.1, steps=968 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 09:59:34 2018\n",
      "53: reward_mean=-10014.8, reward_bound=-4497.4, round_mean=32.1,     distance_mean=84.5, steps=1012 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:00:06 2018\n",
      "54: reward_mean=-9442.1, reward_bound=-4482.0, round_mean=32.0,     distance_mean=84.4, steps=986 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:00:36 2018\n",
      "55: reward_mean=-10086.7, reward_bound=-4455.4, round_mean=32.4,     distance_mean=84.7, steps=1002 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:01:07 2018\n",
      "56: reward_mean=-9352.0, reward_bound=-4428.2, round_mean=31.2,     distance_mean=83.3, steps=966 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:01:36 2018\n",
      "57: reward_mean=-8981.4, reward_bound=-4415.5, round_mean=31.6,     distance_mean=83.7, steps=959 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 10:02:05 2018\n",
      "58: reward_mean=-11396.8, reward_bound=-4588.3, round_mean=32.1,     distance_mean=84.7, steps=1059 \n",
      "------ \n",
      "iter time: 32 s, localtime: Wed Nov 21 10:02:37 2018\n",
      "59: reward_mean=-10243.5, reward_bound=-4733.9, round_mean=32.1,     distance_mean=84.5, steps=1004 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:03:08 2018\n",
      "60: reward_mean=-10752.4, reward_bound=-4689.8, round_mean=31.7,     distance_mean=84.2, steps=1023 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:03:40 2018\n",
      "61: reward_mean=-10563.2, reward_bound=-4608.5, round_mean=31.6,     distance_mean=84.0, steps=1019 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:04:11 2018\n",
      "62: reward_mean=-10233.9, reward_bound=-4581.7, round_mean=32.0,     distance_mean=84.3, steps=1010 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:04:42 2018\n",
      "63: reward_mean=-9474.2, reward_bound=-4680.1, round_mean=31.8,     distance_mean=83.8, steps=977 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:05:11 2018\n",
      "64: reward_mean=-9951.0, reward_bound=-4954.2, round_mean=31.9,     distance_mean=84.3, steps=1005 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:05:42 2018\n",
      "65: reward_mean=-9154.1, reward_bound=-4409.9, round_mean=30.8,     distance_mean=83.3, steps=964 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:06:12 2018\n",
      "66: reward_mean=-9408.1, reward_bound=-4396.5, round_mean=31.8,     distance_mean=84.1, steps=972 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:06:41 2018\n",
      "67: reward_mean=-10208.7, reward_bound=-4495.6, round_mean=31.4,     distance_mean=83.6, steps=1014 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:07:13 2018\n",
      "68: reward_mean=-9780.1, reward_bound=-4735.6, round_mean=31.6,     distance_mean=84.0, steps=992 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:07:45 2018\n",
      "69: reward_mean=-9957.1, reward_bound=-4453.6, round_mean=31.5,     distance_mean=84.0, steps=1004 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:08:16 2018\n",
      "70: reward_mean=-11970.9, reward_bound=-4605.3, round_mean=31.7,     distance_mean=84.4, steps=1068 \n",
      "------ \n",
      "iter time: 32 s, localtime: Wed Nov 21 10:08:49 2018\n",
      "71: reward_mean=-9477.0, reward_bound=-4380.5, round_mean=31.8,     distance_mean=84.2, steps=974 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:09:18 2018\n",
      "72: reward_mean=-9802.8, reward_bound=-4689.4, round_mean=31.3,     distance_mean=84.0, steps=995 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:09:48 2018\n",
      "73: reward_mean=-9631.6, reward_bound=-4446.7, round_mean=31.8,     distance_mean=84.0, steps=984 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:10:19 2018\n",
      "74: reward_mean=-10103.0, reward_bound=-4442.0, round_mean=31.4,     distance_mean=83.8, steps=1011 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:10:50 2018\n",
      "75: reward_mean=-10714.1, reward_bound=-4748.7, round_mean=31.9,     distance_mean=84.4, steps=1033 \n",
      "------ \n",
      "iter time: 32 s, localtime: Wed Nov 21 10:11:22 2018\n",
      "76: reward_mean=-8984.9, reward_bound=-4527.0, round_mean=31.1,     distance_mean=83.3, steps=951 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:11:51 2018\n",
      "77: reward_mean=-9490.3, reward_bound=-4371.0, round_mean=31.3,     distance_mean=84.2, steps=977 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:12:22 2018\n",
      "78: reward_mean=-9961.5, reward_bound=-4457.2, round_mean=31.5,     distance_mean=83.8, steps=981 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:12:52 2018\n",
      "79: reward_mean=-10417.2, reward_bound=-4395.5, round_mean=31.6,     distance_mean=83.6, steps=1015 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:13:23 2018\n",
      "80: reward_mean=-9449.0, reward_bound=-4397.6, round_mean=31.6,     distance_mean=84.3, steps=977 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:13:54 2018\n",
      "81: reward_mean=-10868.4, reward_bound=-4362.8, round_mean=31.8,     distance_mean=84.8, steps=1036 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:14:26 2018\n",
      "82: reward_mean=-9269.0, reward_bound=-4526.9, round_mean=31.4,     distance_mean=83.6, steps=971 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:14:56 2018\n",
      "83: reward_mean=-9106.4, reward_bound=-4327.6, round_mean=32.0,     distance_mean=84.3, steps=963 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:15:25 2018\n",
      "84: reward_mean=-10317.9, reward_bound=-4546.6, round_mean=31.0,     distance_mean=83.1, steps=1006 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:15:56 2018\n",
      "85: reward_mean=-9657.4, reward_bound=-4358.9, round_mean=31.6,     distance_mean=84.0, steps=988 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:16:27 2018\n",
      "86: reward_mean=-10660.5, reward_bound=-4704.3, round_mean=31.6,     distance_mean=83.7, steps=1028 \n",
      "------ \n",
      "iter time: 32 s, localtime: Wed Nov 21 10:16:59 2018\n",
      "87: reward_mean=-9114.5, reward_bound=-4460.6, round_mean=31.3,     distance_mean=83.2, steps=963 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:17:29 2018\n",
      "88: reward_mean=-10409.0, reward_bound=-4342.4, round_mean=31.4,     distance_mean=83.7, steps=1013 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:18:00 2018\n",
      "89: reward_mean=-9644.9, reward_bound=-4389.1, round_mean=31.4,     distance_mean=83.4, steps=983 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:18:30 2018\n",
      "90: reward_mean=-8971.7, reward_bound=-4309.4, round_mean=31.3,     distance_mean=83.3, steps=957 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:18:59 2018\n",
      "91: reward_mean=-10356.1, reward_bound=-4294.4, round_mean=31.5,     distance_mean=83.6, steps=1020 \n",
      "------ \n",
      "iter time: 32 s, localtime: Wed Nov 21 10:19:32 2018\n",
      "92: reward_mean=-9419.5, reward_bound=-4397.9, round_mean=31.3,     distance_mean=83.6, steps=973 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:20:01 2018\n",
      "93: reward_mean=-10595.2, reward_bound=-4476.3, round_mean=31.6,     distance_mean=83.7, steps=1016 \n",
      "------ \n",
      "iter time: 32 s, localtime: Wed Nov 21 10:20:34 2018\n",
      "94: reward_mean=-9385.6, reward_bound=-4356.0, round_mean=31.6,     distance_mean=83.4, steps=970 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:21:03 2018\n",
      "95: reward_mean=-10347.0, reward_bound=-4695.4, round_mean=31.8,     distance_mean=83.9, steps=1020 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:21:35 2018\n",
      "96: reward_mean=-9749.3, reward_bound=-4474.6, round_mean=31.9,     distance_mean=84.0, steps=987 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:22:06 2018\n",
      "97: reward_mean=-9406.4, reward_bound=-4594.5, round_mean=31.8,     distance_mean=84.2, steps=979 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:22:36 2018\n",
      "98: reward_mean=-9749.0, reward_bound=-4476.9, round_mean=31.6,     distance_mean=84.2, steps=987 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:23:06 2018\n",
      "99: reward_mean=-9784.0, reward_bound=-4596.6, round_mean=31.9,     distance_mean=83.8, steps=1000 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:23:36 2018\n",
      "100: reward_mean=-10316.2, reward_bound=-4776.4, round_mean=31.5,     distance_mean=83.7, steps=1010 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:24:08 2018\n",
      "101: reward_mean=-9798.7, reward_bound=-4282.9, round_mean=31.4,     distance_mean=83.4, steps=989 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:24:38 2018\n",
      "102: reward_mean=-12159.3, reward_bound=-4604.6, round_mean=31.9,     distance_mean=84.1, steps=1037 \n",
      "------ \n",
      "iter time: 32 s, localtime: Wed Nov 21 10:25:11 2018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103: reward_mean=-10323.9, reward_bound=-4275.5, round_mean=31.6,     distance_mean=83.9, steps=1011 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:25:41 2018\n",
      "104: reward_mean=-15430.1, reward_bound=-4769.7, round_mean=31.8,     distance_mean=84.0, steps=1061 \n",
      "------ \n",
      "iter time: 34 s, localtime: Wed Nov 21 10:26:15 2018\n",
      "105: reward_mean=-10267.6, reward_bound=-4601.0, round_mean=32.1,     distance_mean=84.4, steps=1012 \n",
      "------ \n",
      "iter time: 32 s, localtime: Wed Nov 21 10:26:47 2018\n",
      "106: reward_mean=-9403.3, reward_bound=-4598.4, round_mean=32.0,     distance_mean=84.5, steps=972 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:27:18 2018\n",
      "107: reward_mean=-9146.0, reward_bound=-4382.1, round_mean=31.8,     distance_mean=83.7, steps=957 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 10:27:47 2018\n",
      "108: reward_mean=-8763.1, reward_bound=-4668.9, round_mean=32.4,     distance_mean=84.8, steps=946 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 10:28:15 2018\n",
      "109: reward_mean=-10587.4, reward_bound=-4434.9, round_mean=32.0,     distance_mean=84.1, steps=1016 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:28:47 2018\n",
      "110: reward_mean=-10743.5, reward_bound=-4365.9, round_mean=32.2,     distance_mean=84.1, steps=1025 \n",
      "------ \n",
      "iter time: 32 s, localtime: Wed Nov 21 10:29:19 2018\n",
      "111: reward_mean=-9943.9, reward_bound=-4456.7, round_mean=32.2,     distance_mean=83.9, steps=1002 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:29:50 2018\n",
      "112: reward_mean=-9439.5, reward_bound=-4483.1, round_mean=31.6,     distance_mean=83.9, steps=967 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:30:21 2018\n",
      "113: reward_mean=-9462.1, reward_bound=-4475.2, round_mean=32.2,     distance_mean=84.4, steps=977 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:30:51 2018\n",
      "114: reward_mean=-10522.6, reward_bound=-4253.2, round_mean=31.9,     distance_mean=84.0, steps=1016 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:31:22 2018\n",
      "115: reward_mean=-9253.5, reward_bound=-4393.7, round_mean=31.8,     distance_mean=84.0, steps=948 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:31:53 2018\n",
      "116: reward_mean=-9156.0, reward_bound=-4243.6, round_mean=31.3,     distance_mean=83.5, steps=954 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:32:22 2018\n",
      "117: reward_mean=-10184.5, reward_bound=-4293.4, round_mean=32.4,     distance_mean=85.1, steps=1005 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:32:53 2018\n",
      "118: reward_mean=-10046.4, reward_bound=-4484.4, round_mean=32.3,     distance_mean=84.2, steps=1002 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:33:23 2018\n",
      "119: reward_mean=-10858.1, reward_bound=-4346.4, round_mean=31.9,     distance_mean=84.2, steps=1023 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:33:55 2018\n",
      "120: reward_mean=-9946.1, reward_bound=-4370.7, round_mean=31.8,     distance_mean=83.4, steps=994 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:34:25 2018\n",
      "121: reward_mean=-10268.8, reward_bound=-4233.3, round_mean=32.0,     distance_mean=84.5, steps=1014 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:34:56 2018\n",
      "122: reward_mean=-9455.6, reward_bound=-4675.3, round_mean=32.3,     distance_mean=84.6, steps=972 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:35:27 2018\n",
      "123: reward_mean=-9524.6, reward_bound=-4380.7, round_mean=32.4,     distance_mean=84.7, steps=975 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:35:59 2018\n",
      "124: reward_mean=-10284.1, reward_bound=-4538.7, round_mean=32.4,     distance_mean=85.1, steps=1011 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:36:29 2018\n",
      "125: reward_mean=-9576.7, reward_bound=-4210.7, round_mean=32.3,     distance_mean=84.3, steps=969 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:36:59 2018\n",
      "126: reward_mean=-10053.3, reward_bound=-4441.2, round_mean=31.5,     distance_mean=83.8, steps=1000 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:37:30 2018\n",
      "127: reward_mean=-9007.4, reward_bound=-4498.3, round_mean=32.0,     distance_mean=84.2, steps=959 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:38:00 2018\n",
      "128: reward_mean=-10225.0, reward_bound=-4187.3, round_mean=31.7,     distance_mean=83.9, steps=1006 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:38:30 2018\n",
      "129: reward_mean=-9904.5, reward_bound=-4384.7, round_mean=32.2,     distance_mean=84.4, steps=993 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:39:00 2018\n",
      "130: reward_mean=-10517.5, reward_bound=-4224.0, round_mean=31.7,     distance_mean=84.0, steps=1014 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:39:31 2018\n",
      "131: reward_mean=-9117.3, reward_bound=-4150.4, round_mean=31.8,     distance_mean=84.1, steps=953 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 10:40:00 2018\n",
      "132: reward_mean=-9812.5, reward_bound=-4570.8, round_mean=31.9,     distance_mean=84.3, steps=995 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:40:30 2018\n",
      "133: reward_mean=-9296.0, reward_bound=-4242.4, round_mean=31.2,     distance_mean=83.6, steps=964 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:41:01 2018\n",
      "134: reward_mean=-9767.8, reward_bound=-4130.4, round_mean=31.8,     distance_mean=84.1, steps=985 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:41:32 2018\n",
      "135: reward_mean=-9707.7, reward_bound=-4125.4, round_mean=32.0,     distance_mean=84.1, steps=984 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:42:01 2018\n",
      "136: reward_mean=-10422.2, reward_bound=-4590.6, round_mean=32.2,     distance_mean=84.7, steps=991 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:42:32 2018\n",
      "137: reward_mean=-9635.8, reward_bound=-4119.5, round_mean=31.6,     distance_mean=83.8, steps=984 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:43:02 2018\n",
      "138: reward_mean=-8732.2, reward_bound=-4117.9, round_mean=31.6,     distance_mean=83.4, steps=936 \n",
      "------ \n",
      "iter time: 27 s, localtime: Wed Nov 21 10:43:30 2018\n",
      "139: reward_mean=-8853.2, reward_bound=-4282.4, round_mean=31.7,     distance_mean=84.0, steps=939 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:44:00 2018\n",
      "140: reward_mean=-10601.7, reward_bound=-4441.1, round_mean=31.4,     distance_mean=83.9, steps=1017 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:44:31 2018\n",
      "141: reward_mean=-9887.6, reward_bound=-4309.7, round_mean=31.5,     distance_mean=83.7, steps=979 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:45:01 2018\n",
      "142: reward_mean=-10297.1, reward_bound=-4521.3, round_mean=31.5,     distance_mean=83.4, steps=1009 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:45:32 2018\n",
      "143: reward_mean=-9807.3, reward_bound=-4470.2, round_mean=32.1,     distance_mean=84.6, steps=996 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:46:02 2018\n",
      "144: reward_mean=-10009.8, reward_bound=-4322.1, round_mean=31.7,     distance_mean=84.1, steps=1003 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:46:33 2018\n",
      "145: reward_mean=-11038.2, reward_bound=-4593.7, round_mean=32.2,     distance_mean=83.8, steps=1022 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:47:04 2018\n",
      "146: reward_mean=-9834.9, reward_bound=-4110.9, round_mean=31.9,     distance_mean=84.5, steps=998 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:47:35 2018\n",
      "147: reward_mean=-9013.4, reward_bound=-4258.7, round_mean=31.5,     distance_mean=83.7, steps=936 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:48:04 2018\n",
      "148: reward_mean=-9510.8, reward_bound=-4097.0, round_mean=31.6,     distance_mean=84.0, steps=965 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:48:34 2018\n",
      "149: reward_mean=-9091.1, reward_bound=-4408.7, round_mean=31.5,     distance_mean=83.7, steps=955 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:49:03 2018\n",
      "150: reward_mean=-9294.6, reward_bound=-4301.5, round_mean=32.2,     distance_mean=84.7, steps=973 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:49:33 2018\n",
      "151: reward_mean=-8692.1, reward_bound=-4131.9, round_mean=31.4,     distance_mean=83.4, steps=933 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 10:50:01 2018\n",
      "152: reward_mean=-9479.4, reward_bound=-4311.2, round_mean=31.7,     distance_mean=84.0, steps=973 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:50:31 2018\n",
      "153: reward_mean=-9882.4, reward_bound=-4236.0, round_mean=32.1,     distance_mean=84.3, steps=981 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:51:01 2018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154: reward_mean=-8830.1, reward_bound=-4270.6, round_mean=31.6,     distance_mean=84.0, steps=942 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:51:31 2018\n",
      "155: reward_mean=-10092.6, reward_bound=-4174.4, round_mean=31.4,     distance_mean=83.6, steps=987 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:52:02 2018\n",
      "156: reward_mean=-9254.6, reward_bound=-4336.8, round_mean=31.7,     distance_mean=83.9, steps=964 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:52:31 2018\n",
      "157: reward_mean=-10395.1, reward_bound=-4651.0, round_mean=31.5,     distance_mean=83.5, steps=1009 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:53:02 2018\n",
      "158: reward_mean=-10021.4, reward_bound=-4743.3, round_mean=32.3,     distance_mean=84.7, steps=993 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:53:33 2018\n",
      "159: reward_mean=-9856.7, reward_bound=-4525.4, round_mean=32.2,     distance_mean=84.6, steps=995 \n",
      "------ \n",
      "iter time: 32 s, localtime: Wed Nov 21 10:54:05 2018\n",
      "160: reward_mean=-10494.9, reward_bound=-4336.8, round_mean=31.9,     distance_mean=84.6, steps=1002 \n",
      "------ \n",
      "iter time: 32 s, localtime: Wed Nov 21 10:54:38 2018\n",
      "161: reward_mean=-9792.8, reward_bound=-4215.6, round_mean=31.7,     distance_mean=84.1, steps=973 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:55:08 2018\n",
      "162: reward_mean=-9410.7, reward_bound=-4199.0, round_mean=31.4,     distance_mean=83.6, steps=970 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:55:38 2018\n",
      "163: reward_mean=-8894.5, reward_bound=-4107.2, round_mean=31.5,     distance_mean=83.9, steps=943 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:56:06 2018\n",
      "164: reward_mean=-10153.8, reward_bound=-4186.2, round_mean=31.5,     distance_mean=83.5, steps=996 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:56:37 2018\n",
      "165: reward_mean=-9603.3, reward_bound=-4497.0, round_mean=31.7,     distance_mean=84.1, steps=979 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:57:08 2018\n",
      "166: reward_mean=-9134.7, reward_bound=-4185.1, round_mean=31.5,     distance_mean=83.7, steps=960 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 10:57:37 2018\n",
      "167: reward_mean=-10179.2, reward_bound=-4805.0, round_mean=32.6,     distance_mean=85.0, steps=1018 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:58:09 2018\n",
      "168: reward_mean=-10153.5, reward_bound=-4514.0, round_mean=32.4,     distance_mean=84.8, steps=998 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:58:39 2018\n",
      "169: reward_mean=-10218.5, reward_bound=-4099.8, round_mean=31.6,     distance_mean=83.9, steps=997 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 10:59:10 2018\n",
      "170: reward_mean=-9970.9, reward_bound=-4512.9, round_mean=32.4,     distance_mean=84.5, steps=997 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 10:59:41 2018\n",
      "171: reward_mean=-9081.3, reward_bound=-4143.4, round_mean=31.6,     distance_mean=83.7, steps=955 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 11:00:09 2018\n",
      "172: reward_mean=-9711.8, reward_bound=-4602.8, round_mean=32.4,     distance_mean=84.4, steps=981 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:00:39 2018\n",
      "173: reward_mean=-10765.4, reward_bound=-4469.1, round_mean=32.2,     distance_mean=84.6, steps=1024 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 11:01:11 2018\n",
      "174: reward_mean=-9171.0, reward_bound=-4703.0, round_mean=32.2,     distance_mean=84.4, steps=962 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:01:41 2018\n",
      "175: reward_mean=-10158.8, reward_bound=-4627.6, round_mean=31.8,     distance_mean=84.1, steps=1003 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 11:02:12 2018\n",
      "176: reward_mean=-9494.4, reward_bound=-4260.8, round_mean=31.7,     distance_mean=83.6, steps=973 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:02:42 2018\n",
      "177: reward_mean=-9575.7, reward_bound=-4485.9, round_mean=32.2,     distance_mean=84.3, steps=989 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:03:12 2018\n",
      "178: reward_mean=-9276.5, reward_bound=-4238.1, round_mean=31.8,     distance_mean=84.2, steps=949 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:03:42 2018\n",
      "179: reward_mean=-9712.3, reward_bound=-4356.2, round_mean=31.6,     distance_mean=83.9, steps=983 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:04:13 2018\n",
      "180: reward_mean=-9352.0, reward_bound=-4086.9, round_mean=31.5,     distance_mean=83.7, steps=963 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:04:43 2018\n",
      "181: reward_mean=-9513.5, reward_bound=-4393.0, round_mean=31.6,     distance_mean=83.3, steps=971 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:05:13 2018\n",
      "182: reward_mean=-10232.2, reward_bound=-4138.0, round_mean=31.6,     distance_mean=83.8, steps=997 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:05:44 2018\n",
      "183: reward_mean=-9115.4, reward_bound=-4106.4, round_mean=31.8,     distance_mean=84.1, steps=946 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:06:13 2018\n",
      "184: reward_mean=-9876.9, reward_bound=-4285.9, round_mean=32.1,     distance_mean=84.2, steps=977 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:06:43 2018\n",
      "185: reward_mean=-10057.0, reward_bound=-4146.0, round_mean=31.7,     distance_mean=83.9, steps=993 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:07:14 2018\n",
      "186: reward_mean=-8943.7, reward_bound=-4303.5, round_mean=31.8,     distance_mean=84.0, steps=950 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 11:07:42 2018\n",
      "187: reward_mean=-9664.2, reward_bound=-4125.6, round_mean=32.0,     distance_mean=84.2, steps=984 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:08:13 2018\n",
      "188: reward_mean=-10096.2, reward_bound=-4768.2, round_mean=31.7,     distance_mean=83.6, steps=1006 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:08:43 2018\n",
      "189: reward_mean=-10644.4, reward_bound=-4255.5, round_mean=32.2,     distance_mean=84.4, steps=1026 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 11:09:15 2018\n",
      "190: reward_mean=-10204.0, reward_bound=-4202.4, round_mean=32.3,     distance_mean=84.6, steps=992 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:09:45 2018\n",
      "191: reward_mean=-10581.7, reward_bound=-4890.5, round_mean=31.8,     distance_mean=83.8, steps=1028 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 11:10:16 2018\n",
      "192: reward_mean=-9577.8, reward_bound=-4456.5, round_mean=31.9,     distance_mean=83.6, steps=981 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:10:46 2018\n",
      "193: reward_mean=-10127.4, reward_bound=-4379.1, round_mean=30.8,     distance_mean=83.0, steps=1004 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:11:17 2018\n",
      "194: reward_mean=-9381.2, reward_bound=-4212.2, round_mean=31.8,     distance_mean=84.1, steps=971 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:11:47 2018\n",
      "195: reward_mean=-9249.8, reward_bound=-4457.3, round_mean=31.7,     distance_mean=83.8, steps=967 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:12:16 2018\n",
      "196: reward_mean=-9272.1, reward_bound=-4326.5, round_mean=32.1,     distance_mean=84.4, steps=966 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:12:46 2018\n",
      "197: reward_mean=-9364.6, reward_bound=-4075.1, round_mean=31.9,     distance_mean=84.1, steps=963 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:13:16 2018\n",
      "198: reward_mean=-8814.9, reward_bound=-4122.1, round_mean=32.0,     distance_mean=84.0, steps=943 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 11:13:44 2018\n",
      "199: reward_mean=-9491.6, reward_bound=-4055.6, round_mean=31.8,     distance_mean=84.0, steps=961 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:14:14 2018\n",
      "200: reward_mean=-9529.1, reward_bound=-4279.5, round_mean=32.2,     distance_mean=84.2, steps=979 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:14:44 2018\n",
      "201: reward_mean=-10658.3, reward_bound=-4374.1, round_mean=32.2,     distance_mean=84.3, steps=1013 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 11:15:15 2018\n",
      "202: reward_mean=-10828.6, reward_bound=-4043.1, round_mean=31.8,     distance_mean=84.1, steps=1014 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 11:15:47 2018\n",
      "203: reward_mean=-9833.7, reward_bound=-4417.4, round_mean=31.7,     distance_mean=84.0, steps=954 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:16:17 2018\n",
      "204: reward_mean=-9639.1, reward_bound=-4291.0, round_mean=31.4,     distance_mean=83.4, steps=979 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:16:48 2018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205: reward_mean=-9316.6, reward_bound=-4228.4, round_mean=32.0,     distance_mean=84.1, steps=955 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:17:17 2018\n",
      "206: reward_mean=-9674.0, reward_bound=-4473.5, round_mean=31.7,     distance_mean=84.3, steps=971 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:17:47 2018\n",
      "207: reward_mean=-9949.1, reward_bound=-4303.8, round_mean=31.8,     distance_mean=84.0, steps=984 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 11:18:18 2018\n",
      "208: reward_mean=-10058.3, reward_bound=-4379.8, round_mean=31.9,     distance_mean=84.0, steps=987 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:18:48 2018\n",
      "209: reward_mean=-9162.5, reward_bound=-4462.0, round_mean=31.8,     distance_mean=84.0, steps=952 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:19:17 2018\n",
      "210: reward_mean=-9150.0, reward_bound=-4224.6, round_mean=31.4,     distance_mean=83.5, steps=950 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:19:46 2018\n",
      "211: reward_mean=-9858.6, reward_bound=-4266.4, round_mean=32.0,     distance_mean=84.8, steps=988 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:20:17 2018\n",
      "212: reward_mean=-9512.6, reward_bound=-4031.0, round_mean=31.9,     distance_mean=84.0, steps=976 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:20:48 2018\n",
      "213: reward_mean=-9004.9, reward_bound=-4267.1, round_mean=31.6,     distance_mean=83.6, steps=949 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 11:21:16 2018\n",
      "214: reward_mean=-9389.8, reward_bound=-4297.6, round_mean=31.5,     distance_mean=83.5, steps=973 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:21:46 2018\n",
      "215: reward_mean=-10263.6, reward_bound=-4021.3, round_mean=31.9,     distance_mean=84.4, steps=974 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:22:17 2018\n",
      "216: reward_mean=-9748.6, reward_bound=-4216.3, round_mean=31.7,     distance_mean=83.9, steps=985 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:22:47 2018\n",
      "217: reward_mean=-8809.1, reward_bound=-3998.3, round_mean=31.8,     distance_mean=84.0, steps=939 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 11:23:16 2018\n",
      "218: reward_mean=-9492.4, reward_bound=-4190.4, round_mean=32.1,     distance_mean=84.1, steps=970 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:23:46 2018\n",
      "219: reward_mean=-10869.1, reward_bound=-4231.9, round_mean=31.9,     distance_mean=83.8, steps=1018 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 11:24:17 2018\n",
      "220: reward_mean=-9451.9, reward_bound=-4177.6, round_mean=31.8,     distance_mean=83.5, steps=957 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:24:48 2018\n",
      "221: reward_mean=-8845.0, reward_bound=-4105.0, round_mean=31.1,     distance_mean=83.3, steps=939 \n",
      "------ \n",
      "iter time: 27 s, localtime: Wed Nov 21 11:25:16 2018\n",
      "222: reward_mean=-10216.7, reward_bound=-4327.4, round_mean=32.2,     distance_mean=84.5, steps=995 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 11:25:47 2018\n",
      "223: reward_mean=-9865.0, reward_bound=-4242.9, round_mean=32.1,     distance_mean=84.0, steps=988 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:26:17 2018\n",
      "224: reward_mean=-9023.7, reward_bound=-4196.5, round_mean=32.0,     distance_mean=84.4, steps=945 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 11:26:46 2018\n",
      "225: reward_mean=-9776.3, reward_bound=-4238.6, round_mean=32.1,     distance_mean=84.0, steps=968 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:27:16 2018\n",
      "226: reward_mean=-9261.4, reward_bound=-4393.5, round_mean=31.3,     distance_mean=82.9, steps=958 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 11:27:45 2018\n",
      "227: reward_mean=-9100.2, reward_bound=-4576.1, round_mean=31.9,     distance_mean=84.2, steps=960 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 11:28:14 2018\n",
      "228: reward_mean=-9918.0, reward_bound=-4096.9, round_mean=31.4,     distance_mean=83.5, steps=982 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:28:44 2018\n",
      "229: reward_mean=-9743.4, reward_bound=-4290.6, round_mean=31.9,     distance_mean=83.8, steps=986 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:29:14 2018\n",
      "230: reward_mean=-9459.0, reward_bound=-4238.9, round_mean=32.1,     distance_mean=84.4, steps=973 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 11:29:44 2018\n",
      "231: reward_mean=-9154.2, reward_bound=-4374.8, round_mean=32.0,     distance_mean=83.7, steps=951 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 11:30:14 2018\n",
      "232: reward_mean=-9619.3, reward_bound=-4359.6, round_mean=31.6,     distance_mean=83.5, steps=966 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 11:30:45 2018\n",
      "233: reward_mean=-10256.9, reward_bound=-4051.6, round_mean=32.1,     distance_mean=84.4, steps=994 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 11:31:17 2018\n",
      "234: reward_mean=-9614.6, reward_bound=-3989.3, round_mean=31.3,     distance_mean=83.6, steps=980 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:31:47 2018\n",
      "235: reward_mean=-9244.4, reward_bound=-3982.5, round_mean=32.0,     distance_mean=84.3, steps=961 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:32:17 2018\n",
      "236: reward_mean=-9307.0, reward_bound=-4321.9, round_mean=31.5,     distance_mean=83.6, steps=958 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:32:46 2018\n",
      "237: reward_mean=-9359.9, reward_bound=-4046.6, round_mean=31.7,     distance_mean=84.2, steps=961 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:33:17 2018\n",
      "238: reward_mean=-8644.9, reward_bound=-4067.9, round_mean=31.0,     distance_mean=82.9, steps=927 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 11:33:45 2018\n",
      "239: reward_mean=-10841.1, reward_bound=-4120.3, round_mean=31.6,     distance_mean=83.7, steps=998 \n",
      "------ \n",
      "iter time: 32 s, localtime: Wed Nov 21 11:34:17 2018\n",
      "240: reward_mean=-9589.6, reward_bound=-4188.3, round_mean=31.8,     distance_mean=83.7, steps=974 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:34:47 2018\n",
      "241: reward_mean=-10116.9, reward_bound=-4149.7, round_mean=31.8,     distance_mean=83.5, steps=989 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 11:35:19 2018\n",
      "242: reward_mean=-8548.6, reward_bound=-4260.6, round_mean=32.1,     distance_mean=84.4, steps=933 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 11:35:47 2018\n",
      "243: reward_mean=-8669.0, reward_bound=-4317.9, round_mean=31.8,     distance_mean=83.9, steps=933 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 11:36:16 2018\n",
      "244: reward_mean=-10134.9, reward_bound=-4598.4, round_mean=32.1,     distance_mean=84.5, steps=996 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:36:47 2018\n",
      "245: reward_mean=-10602.8, reward_bound=-4454.2, round_mean=31.7,     distance_mean=83.7, steps=1006 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 11:37:18 2018\n",
      "246: reward_mean=-9197.2, reward_bound=-4602.7, round_mean=31.9,     distance_mean=83.8, steps=965 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:37:48 2018\n",
      "247: reward_mean=-10048.4, reward_bound=-3965.8, round_mean=31.9,     distance_mean=83.8, steps=983 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:38:18 2018\n",
      "248: reward_mean=-9579.2, reward_bound=-4117.4, round_mean=32.5,     distance_mean=84.3, steps=971 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:38:49 2018\n",
      "249: reward_mean=-10040.7, reward_bound=-4413.1, round_mean=31.6,     distance_mean=83.9, steps=991 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:39:19 2018\n",
      "250: reward_mean=-10416.0, reward_bound=-4298.9, round_mean=32.2,     distance_mean=84.4, steps=1017 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 11:39:50 2018\n",
      "251: reward_mean=-9233.6, reward_bound=-4121.7, round_mean=32.0,     distance_mean=84.2, steps=951 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 11:40:20 2018\n",
      "252: reward_mean=-9014.5, reward_bound=-4402.2, round_mean=32.1,     distance_mean=84.1, steps=952 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:40:50 2018\n",
      "253: reward_mean=-9589.0, reward_bound=-4372.8, round_mean=32.3,     distance_mean=84.3, steps=973 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:41:19 2018\n",
      "254: reward_mean=-9778.7, reward_bound=-4122.6, round_mean=32.3,     distance_mean=84.4, steps=987 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:41:49 2018\n",
      "255: reward_mean=-8944.5, reward_bound=-3986.6, round_mean=32.0,     distance_mean=83.8, steps=941 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 11:42:18 2018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256: reward_mean=-9892.6, reward_bound=-3964.0, round_mean=31.8,     distance_mean=83.6, steps=981 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:42:49 2018\n",
      "257: reward_mean=-8990.8, reward_bound=-4071.3, round_mean=31.4,     distance_mean=83.5, steps=944 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:43:18 2018\n",
      "258: reward_mean=-8767.7, reward_bound=-4065.0, round_mean=31.6,     distance_mean=83.3, steps=935 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 11:43:46 2018\n",
      "259: reward_mean=-10278.9, reward_bound=-4242.0, round_mean=31.7,     distance_mean=83.5, steps=1002 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:44:17 2018\n",
      "260: reward_mean=-10256.0, reward_bound=-3952.4, round_mean=31.8,     distance_mean=83.8, steps=991 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 11:44:49 2018\n",
      "261: reward_mean=-9854.4, reward_bound=-4298.7, round_mean=31.8,     distance_mean=84.0, steps=985 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:45:19 2018\n",
      "262: reward_mean=-10413.2, reward_bound=-4477.3, round_mean=31.6,     distance_mean=83.6, steps=999 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:45:49 2018\n",
      "263: reward_mean=-9094.7, reward_bound=-4288.5, round_mean=32.0,     distance_mean=84.4, steps=947 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:46:19 2018\n",
      "264: reward_mean=-9098.6, reward_bound=-3983.9, round_mean=31.9,     distance_mean=84.2, steps=949 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 11:46:48 2018\n",
      "265: reward_mean=-9714.0, reward_bound=-4489.9, round_mean=32.0,     distance_mean=83.9, steps=979 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:47:18 2018\n",
      "266: reward_mean=-10417.1, reward_bound=-4487.3, round_mean=32.1,     distance_mean=84.0, steps=1015 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 11:47:49 2018\n",
      "267: reward_mean=-9822.1, reward_bound=-4228.8, round_mean=31.7,     distance_mean=83.9, steps=985 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:48:20 2018\n",
      "268: reward_mean=-9336.3, reward_bound=-3977.4, round_mean=32.1,     distance_mean=84.0, steps=957 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:48:49 2018\n",
      "269: reward_mean=-10297.7, reward_bound=-3992.9, round_mean=31.7,     distance_mean=83.7, steps=1003 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 11:49:21 2018\n",
      "270: reward_mean=-11054.8, reward_bound=-3966.2, round_mean=31.7,     distance_mean=83.8, steps=1007 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 11:49:52 2018\n",
      "271: reward_mean=-10124.2, reward_bound=-4210.7, round_mean=31.5,     distance_mean=83.4, steps=989 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:50:22 2018\n",
      "272: reward_mean=-9971.5, reward_bound=-4228.5, round_mean=31.8,     distance_mean=83.8, steps=981 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:50:53 2018\n",
      "273: reward_mean=-9709.6, reward_bound=-4096.8, round_mean=32.0,     distance_mean=83.9, steps=977 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:51:24 2018\n",
      "274: reward_mean=-9684.6, reward_bound=-4251.9, round_mean=32.1,     distance_mean=84.3, steps=973 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:51:54 2018\n",
      "275: reward_mean=-8988.9, reward_bound=-4284.1, round_mean=32.0,     distance_mean=83.7, steps=939 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:52:23 2018\n",
      "276: reward_mean=-8857.6, reward_bound=-4064.5, round_mean=32.2,     distance_mean=84.2, steps=937 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:52:52 2018\n",
      "277: reward_mean=-9941.9, reward_bound=-3983.3, round_mean=32.3,     distance_mean=84.5, steps=982 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 11:53:23 2018\n",
      "278: reward_mean=-10010.1, reward_bound=-4464.4, round_mean=32.3,     distance_mean=84.4, steps=993 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:53:54 2018\n",
      "279: reward_mean=-9299.2, reward_bound=-4155.9, round_mean=32.6,     distance_mean=85.2, steps=961 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 11:54:23 2018\n",
      "280: reward_mean=-9032.2, reward_bound=-4180.1, round_mean=32.3,     distance_mean=84.0, steps=949 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 11:54:51 2018\n",
      "281: reward_mean=-10434.0, reward_bound=-4042.9, round_mean=32.5,     distance_mean=84.6, steps=1001 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 11:55:23 2018\n",
      "282: reward_mean=-10814.5, reward_bound=-4207.3, round_mean=31.9,     distance_mean=84.0, steps=1014 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:55:54 2018\n",
      "283: reward_mean=-9423.5, reward_bound=-4109.1, round_mean=32.1,     distance_mean=84.3, steps=969 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:56:24 2018\n",
      "284: reward_mean=-9961.1, reward_bound=-4302.1, round_mean=32.2,     distance_mean=84.8, steps=982 \n",
      "------ \n",
      "iter time: 32 s, localtime: Wed Nov 21 11:56:56 2018\n",
      "285: reward_mean=-9072.5, reward_bound=-4434.9, round_mean=31.9,     distance_mean=83.8, steps=953 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:57:26 2018\n",
      "286: reward_mean=-9375.5, reward_bound=-4227.6, round_mean=32.4,     distance_mean=84.3, steps=965 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:57:56 2018\n",
      "287: reward_mean=-9577.8, reward_bound=-4223.2, round_mean=32.0,     distance_mean=83.9, steps=984 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:58:26 2018\n",
      "288: reward_mean=-10317.6, reward_bound=-4439.0, round_mean=31.7,     distance_mean=83.7, steps=1003 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 11:58:58 2018\n",
      "289: reward_mean=-9835.3, reward_bound=-4053.2, round_mean=31.7,     distance_mean=83.5, steps=987 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 11:59:28 2018\n",
      "290: reward_mean=-9268.0, reward_bound=-4241.1, round_mean=32.1,     distance_mean=84.0, steps=958 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 11:59:58 2018\n",
      "291: reward_mean=-9763.3, reward_bound=-4162.0, round_mean=31.5,     distance_mean=83.6, steps=979 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:00:28 2018\n",
      "292: reward_mean=-9525.4, reward_bound=-3948.1, round_mean=32.4,     distance_mean=84.4, steps=963 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:00:57 2018\n",
      "293: reward_mean=-9736.2, reward_bound=-3962.0, round_mean=32.2,     distance_mean=84.0, steps=970 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:01:27 2018\n",
      "294: reward_mean=-10256.3, reward_bound=-3946.6, round_mean=32.6,     distance_mean=84.9, steps=993 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 12:01:58 2018\n",
      "295: reward_mean=-10027.6, reward_bound=-3979.0, round_mean=31.6,     distance_mean=83.6, steps=983 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:02:28 2018\n",
      "296: reward_mean=-9166.9, reward_bound=-4177.2, round_mean=31.6,     distance_mean=83.6, steps=952 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:02:58 2018\n",
      "297: reward_mean=-8945.8, reward_bound=-4265.9, round_mean=32.2,     distance_mean=84.1, steps=946 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 12:03:27 2018\n",
      "298: reward_mean=-10198.6, reward_bound=-4340.7, round_mean=31.2,     distance_mean=83.4, steps=982 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:03:58 2018\n",
      "299: reward_mean=-8887.1, reward_bound=-4102.8, round_mean=31.6,     distance_mean=83.4, steps=947 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 12:04:26 2018\n",
      "300: reward_mean=-10120.6, reward_bound=-4221.4, round_mean=31.6,     distance_mean=83.5, steps=990 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 12:04:57 2018\n",
      "301: reward_mean=-9936.8, reward_bound=-4160.5, round_mean=31.1,     distance_mean=82.8, steps=977 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 12:05:29 2018\n",
      "302: reward_mean=-9974.9, reward_bound=-3934.8, round_mean=32.1,     distance_mean=84.3, steps=986 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:05:59 2018\n",
      "303: reward_mean=-9526.4, reward_bound=-4195.6, round_mean=32.0,     distance_mean=84.9, steps=969 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:06:29 2018\n",
      "304: reward_mean=-10194.1, reward_bound=-4035.7, round_mean=32.3,     distance_mean=84.4, steps=982 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 12:07:00 2018\n",
      "305: reward_mean=-10146.4, reward_bound=-4214.2, round_mean=32.3,     distance_mean=84.0, steps=984 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:07:30 2018\n",
      "306: reward_mean=-10402.5, reward_bound=-3913.9, round_mean=32.0,     distance_mean=84.0, steps=974 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:08:01 2018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307: reward_mean=-9296.2, reward_bound=-3926.1, round_mean=32.0,     distance_mean=84.2, steps=956 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:08:30 2018\n",
      "308: reward_mean=-9811.9, reward_bound=-3933.0, round_mean=31.5,     distance_mean=83.7, steps=984 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:09:00 2018\n",
      "309: reward_mean=-9023.5, reward_bound=-4110.4, round_mean=32.4,     distance_mean=84.6, steps=931 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 12:09:29 2018\n",
      "310: reward_mean=-9659.0, reward_bound=-4225.6, round_mean=31.4,     distance_mean=83.3, steps=965 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:09:59 2018\n",
      "311: reward_mean=-9588.9, reward_bound=-4260.5, round_mean=31.9,     distance_mean=84.1, steps=969 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:10:30 2018\n",
      "312: reward_mean=-9136.2, reward_bound=-4138.1, round_mean=31.7,     distance_mean=83.9, steps=953 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:10:59 2018\n",
      "313: reward_mean=-9203.2, reward_bound=-4054.0, round_mean=31.5,     distance_mean=83.4, steps=954 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 12:11:28 2018\n",
      "314: reward_mean=-9053.1, reward_bound=-3909.4, round_mean=32.1,     distance_mean=84.0, steps=951 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:11:58 2018\n",
      "315: reward_mean=-9111.6, reward_bound=-3889.9, round_mean=31.4,     distance_mean=83.5, steps=942 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:12:27 2018\n",
      "316: reward_mean=-10287.1, reward_bound=-4360.8, round_mean=31.9,     distance_mean=84.3, steps=982 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 12:12:58 2018\n",
      "317: reward_mean=-9822.2, reward_bound=-4385.0, round_mean=32.1,     distance_mean=84.7, steps=974 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:13:29 2018\n",
      "318: reward_mean=-9834.5, reward_bound=-4088.8, round_mean=32.2,     distance_mean=84.7, steps=983 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 12:13:59 2018\n",
      "319: reward_mean=-9319.7, reward_bound=-3929.0, round_mean=31.7,     distance_mean=83.9, steps=957 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:14:29 2018\n",
      "320: reward_mean=-9732.1, reward_bound=-4036.5, round_mean=32.0,     distance_mean=84.0, steps=984 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:14:59 2018\n",
      "321: reward_mean=-8075.5, reward_bound=-4094.6, round_mean=31.1,     distance_mean=83.2, steps=898 \n",
      "------ \n",
      "iter time: 27 s, localtime: Wed Nov 21 12:15:27 2018\n",
      "322: reward_mean=-9805.5, reward_bound=-3881.3, round_mean=31.8,     distance_mean=84.0, steps=972 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:15:57 2018\n",
      "323: reward_mean=-9118.0, reward_bound=-4128.2, round_mean=32.0,     distance_mean=84.2, steps=946 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 12:16:27 2018\n",
      "324: reward_mean=-9721.9, reward_bound=-3948.5, round_mean=32.2,     distance_mean=84.5, steps=973 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:16:57 2018\n",
      "325: reward_mean=-10292.8, reward_bound=-4126.4, round_mean=32.2,     distance_mean=84.7, steps=999 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:17:27 2018\n",
      "326: reward_mean=-10118.5, reward_bound=-4161.6, round_mean=31.9,     distance_mean=84.2, steps=975 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:17:57 2018\n",
      "327: reward_mean=-9395.9, reward_bound=-4304.7, round_mean=31.7,     distance_mean=83.8, steps=964 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:18:27 2018\n",
      "328: reward_mean=-9883.2, reward_bound=-3864.1, round_mean=31.7,     distance_mean=83.5, steps=974 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:18:57 2018\n",
      "329: reward_mean=-10099.0, reward_bound=-4021.5, round_mean=31.9,     distance_mean=84.1, steps=977 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:19:27 2018\n",
      "330: reward_mean=-9493.4, reward_bound=-3973.6, round_mean=32.3,     distance_mean=84.8, steps=966 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:19:56 2018\n",
      "331: reward_mean=-10593.3, reward_bound=-4102.6, round_mean=32.7,     distance_mean=85.3, steps=1020 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 12:20:28 2018\n",
      "332: reward_mean=-9934.3, reward_bound=-3856.0, round_mean=32.1,     distance_mean=84.0, steps=977 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:20:58 2018\n",
      "333: reward_mean=-9332.4, reward_bound=-4338.6, round_mean=32.8,     distance_mean=85.1, steps=964 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:21:28 2018\n",
      "334: reward_mean=-9322.6, reward_bound=-4171.9, round_mean=31.9,     distance_mean=84.0, steps=949 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:21:58 2018\n",
      "335: reward_mean=-9543.3, reward_bound=-4311.6, round_mean=32.2,     distance_mean=84.2, steps=975 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:22:29 2018\n",
      "336: reward_mean=-9602.7, reward_bound=-4189.9, round_mean=32.2,     distance_mean=84.6, steps=984 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:22:58 2018\n",
      "337: reward_mean=-9595.5, reward_bound=-4173.4, round_mean=32.1,     distance_mean=84.4, steps=975 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:23:29 2018\n",
      "338: reward_mean=-8735.3, reward_bound=-4413.7, round_mean=32.1,     distance_mean=84.3, steps=937 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 12:23:57 2018\n",
      "339: reward_mean=-8660.6, reward_bound=-4021.4, round_mean=31.4,     distance_mean=83.7, steps=921 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 12:24:26 2018\n",
      "340: reward_mean=-9006.6, reward_bound=-4262.2, round_mean=32.2,     distance_mean=84.6, steps=947 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:24:56 2018\n",
      "341: reward_mean=-9579.0, reward_bound=-3901.5, round_mean=32.4,     distance_mean=84.3, steps=968 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:25:26 2018\n",
      "342: reward_mean=-9896.0, reward_bound=-3991.2, round_mean=31.8,     distance_mean=84.1, steps=981 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:25:57 2018\n",
      "343: reward_mean=-8452.6, reward_bound=-4123.6, round_mean=32.2,     distance_mean=84.3, steps=920 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 12:26:26 2018\n",
      "344: reward_mean=-10053.7, reward_bound=-3891.6, round_mean=31.6,     distance_mean=83.6, steps=987 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:26:56 2018\n",
      "345: reward_mean=-9320.5, reward_bound=-3940.3, round_mean=32.2,     distance_mean=84.8, steps=952 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:27:25 2018\n",
      "346: reward_mean=-10418.3, reward_bound=-4154.4, round_mean=31.9,     distance_mean=84.4, steps=1011 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 12:27:57 2018\n",
      "347: reward_mean=-10027.7, reward_bound=-3851.1, round_mean=31.7,     distance_mean=83.9, steps=973 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:28:27 2018\n",
      "348: reward_mean=-8767.9, reward_bound=-3866.9, round_mean=31.7,     distance_mean=84.3, steps=926 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:28:56 2018\n",
      "349: reward_mean=-8861.5, reward_bound=-3921.9, round_mean=31.8,     distance_mean=84.3, steps=932 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 12:29:25 2018\n",
      "350: reward_mean=-10033.3, reward_bound=-4096.7, round_mean=31.7,     distance_mean=84.1, steps=987 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 12:29:56 2018\n",
      "351: reward_mean=-8653.7, reward_bound=-4203.9, round_mean=31.5,     distance_mean=83.8, steps=924 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 12:30:25 2018\n",
      "352: reward_mean=-9621.0, reward_bound=-4451.5, round_mean=31.5,     distance_mean=83.5, steps=976 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:30:55 2018\n",
      "353: reward_mean=-9987.7, reward_bound=-4187.4, round_mean=31.7,     distance_mean=83.6, steps=987 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:31:25 2018\n",
      "354: reward_mean=-9016.5, reward_bound=-4129.1, round_mean=32.0,     distance_mean=84.5, steps=949 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:31:54 2018\n",
      "355: reward_mean=-9243.1, reward_bound=-4072.0, round_mean=31.8,     distance_mean=84.2, steps=950 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:32:23 2018\n",
      "356: reward_mean=-9684.0, reward_bound=-4305.1, round_mean=31.9,     distance_mean=84.3, steps=982 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:32:53 2018\n",
      "357: reward_mean=-8892.4, reward_bound=-4273.1, round_mean=32.1,     distance_mean=84.3, steps=940 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 12:33:21 2018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358: reward_mean=-9847.7, reward_bound=-3977.0, round_mean=31.5,     distance_mean=83.9, steps=984 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 12:33:52 2018\n",
      "359: reward_mean=-9641.2, reward_bound=-4336.6, round_mean=32.2,     distance_mean=84.7, steps=968 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:34:21 2018\n",
      "360: reward_mean=-9085.2, reward_bound=-3826.4, round_mean=32.2,     distance_mean=84.6, steps=948 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 12:34:50 2018\n",
      "361: reward_mean=-9701.2, reward_bound=-4069.9, round_mean=32.3,     distance_mean=84.5, steps=969 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:35:20 2018\n",
      "362: reward_mean=-10597.1, reward_bound=-3815.0, round_mean=32.3,     distance_mean=84.8, steps=1009 \n",
      "------ \n",
      "iter time: 32 s, localtime: Wed Nov 21 12:35:52 2018\n",
      "363: reward_mean=-10047.7, reward_bound=-4302.8, round_mean=32.3,     distance_mean=84.9, steps=991 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 12:36:23 2018\n",
      "364: reward_mean=-10152.5, reward_bound=-3781.9, round_mean=31.8,     distance_mean=83.9, steps=992 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 12:36:54 2018\n",
      "365: reward_mean=-9584.5, reward_bound=-4053.9, round_mean=31.8,     distance_mean=83.8, steps=969 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:37:24 2018\n",
      "366: reward_mean=-10147.4, reward_bound=-4130.0, round_mean=32.2,     distance_mean=84.0, steps=986 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:37:54 2018\n",
      "367: reward_mean=-9392.2, reward_bound=-4269.6, round_mean=31.7,     distance_mean=83.7, steps=961 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:38:24 2018\n",
      "368: reward_mean=-9307.0, reward_bound=-3976.4, round_mean=31.6,     distance_mean=83.8, steps=956 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:38:54 2018\n",
      "369: reward_mean=-8749.0, reward_bound=-4114.6, round_mean=31.2,     distance_mean=83.6, steps=928 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:39:23 2018\n",
      "370: reward_mean=-9571.4, reward_bound=-3990.1, round_mean=31.6,     distance_mean=84.1, steps=955 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:39:52 2018\n",
      "371: reward_mean=-9921.5, reward_bound=-3828.6, round_mean=32.6,     distance_mean=85.3, steps=980 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:40:23 2018\n",
      "372: reward_mean=-10096.3, reward_bound=-4054.0, round_mean=32.1,     distance_mean=84.5, steps=996 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 12:40:55 2018\n",
      "373: reward_mean=-8933.6, reward_bound=-4510.3, round_mean=31.5,     distance_mean=83.8, steps=938 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:41:24 2018\n",
      "374: reward_mean=-9715.8, reward_bound=-4016.6, round_mean=32.0,     distance_mean=84.8, steps=968 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:41:54 2018\n",
      "375: reward_mean=-9309.6, reward_bound=-3982.9, round_mean=31.9,     distance_mean=84.2, steps=958 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:42:23 2018\n",
      "376: reward_mean=-9244.1, reward_bound=-4168.3, round_mean=31.8,     distance_mean=84.3, steps=943 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:42:53 2018\n",
      "377: reward_mean=-10205.1, reward_bound=-4241.3, round_mean=31.9,     distance_mean=84.5, steps=999 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 12:43:24 2018\n",
      "378: reward_mean=-9393.2, reward_bound=-4105.1, round_mean=31.7,     distance_mean=83.7, steps=955 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:43:54 2018\n",
      "379: reward_mean=-8868.9, reward_bound=-3761.6, round_mean=31.5,     distance_mean=83.9, steps=934 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 12:44:23 2018\n",
      "380: reward_mean=-10594.1, reward_bound=-3972.9, round_mean=32.2,     distance_mean=84.1, steps=1000 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 12:44:54 2018\n",
      "381: reward_mean=-9074.4, reward_bound=-3879.2, round_mean=31.4,     distance_mean=83.9, steps=947 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 12:45:23 2018\n",
      "382: reward_mean=-9240.3, reward_bound=-3725.3, round_mean=31.4,     distance_mean=83.4, steps=956 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:45:53 2018\n",
      "383: reward_mean=-10435.7, reward_bound=-4412.4, round_mean=31.7,     distance_mean=83.8, steps=1003 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 12:46:25 2018\n",
      "384: reward_mean=-10165.7, reward_bound=-3853.4, round_mean=31.8,     distance_mean=84.0, steps=986 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 12:46:56 2018\n",
      "385: reward_mean=-9805.0, reward_bound=-3967.4, round_mean=32.1,     distance_mean=84.2, steps=972 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:47:27 2018\n",
      "386: reward_mean=-8881.0, reward_bound=-3859.6, round_mean=31.9,     distance_mean=84.2, steps=938 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 12:47:55 2018\n",
      "387: reward_mean=-10225.5, reward_bound=-3908.9, round_mean=31.6,     distance_mean=83.7, steps=999 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:48:25 2018\n",
      "388: reward_mean=-10727.3, reward_bound=-4035.8, round_mean=32.1,     distance_mean=84.1, steps=1000 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 12:48:57 2018\n",
      "389: reward_mean=-9694.9, reward_bound=-4094.1, round_mean=31.6,     distance_mean=83.7, steps=978 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:49:28 2018\n",
      "390: reward_mean=-9384.1, reward_bound=-4035.3, round_mean=32.1,     distance_mean=84.4, steps=950 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 12:49:59 2018\n",
      "391: reward_mean=-9187.8, reward_bound=-3930.5, round_mean=32.0,     distance_mean=84.5, steps=955 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:50:29 2018\n",
      "392: reward_mean=-9697.9, reward_bound=-3834.3, round_mean=31.2,     distance_mean=83.9, steps=958 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:50:59 2018\n",
      "393: reward_mean=-10001.7, reward_bound=-3886.3, round_mean=31.8,     distance_mean=84.3, steps=996 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:51:30 2018\n",
      "394: reward_mean=-9349.0, reward_bound=-4308.0, round_mean=32.5,     distance_mean=84.7, steps=965 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:52:00 2018\n",
      "395: reward_mean=-8756.4, reward_bound=-3953.0, round_mean=32.1,     distance_mean=84.6, steps=935 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 12:52:28 2018\n",
      "396: reward_mean=-9698.5, reward_bound=-3803.6, round_mean=31.7,     distance_mean=83.7, steps=968 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:52:58 2018\n",
      "397: reward_mean=-9001.9, reward_bound=-4060.8, round_mean=31.5,     distance_mean=83.9, steps=940 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:53:28 2018\n",
      "398: reward_mean=-9986.8, reward_bound=-3902.0, round_mean=31.8,     distance_mean=84.0, steps=969 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:53:58 2018\n",
      "399: reward_mean=-8851.3, reward_bound=-3899.8, round_mean=32.0,     distance_mean=84.3, steps=933 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:54:28 2018\n",
      "400: reward_mean=-9474.4, reward_bound=-3752.5, round_mean=32.1,     distance_mean=84.4, steps=969 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:54:57 2018\n",
      "401: reward_mean=-9143.5, reward_bound=-4064.1, round_mean=32.2,     distance_mean=84.7, steps=947 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:55:27 2018\n",
      "402: reward_mean=-10086.2, reward_bound=-3786.6, round_mean=31.9,     distance_mean=84.2, steps=977 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 12:55:59 2018\n",
      "403: reward_mean=-9452.7, reward_bound=-3923.4, round_mean=31.7,     distance_mean=84.1, steps=960 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:56:28 2018\n",
      "404: reward_mean=-9551.5, reward_bound=-3824.7, round_mean=32.1,     distance_mean=84.6, steps=960 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:56:57 2018\n",
      "405: reward_mean=-10044.4, reward_bound=-4014.1, round_mean=31.8,     distance_mean=84.1, steps=978 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:57:27 2018\n",
      "406: reward_mean=-9101.3, reward_bound=-3995.4, round_mean=32.5,     distance_mean=84.5, steps=947 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 12:57:56 2018\n",
      "407: reward_mean=-9688.2, reward_bound=-4077.8, round_mean=32.0,     distance_mean=83.9, steps=967 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 12:58:27 2018\n",
      "408: reward_mean=-8569.9, reward_bound=-4100.4, round_mean=32.3,     distance_mean=84.8, steps=924 \n",
      "------ \n",
      "iter time: 27 s, localtime: Wed Nov 21 12:58:54 2018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409: reward_mean=-10907.5, reward_bound=-4037.0, round_mean=31.6,     distance_mean=83.8, steps=1010 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 12:59:26 2018\n",
      "410: reward_mean=-9466.0, reward_bound=-4000.5, round_mean=32.0,     distance_mean=84.6, steps=968 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 12:59:56 2018\n",
      "411: reward_mean=-9154.2, reward_bound=-3809.6, round_mean=31.8,     distance_mean=83.8, steps=938 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 13:00:24 2018\n",
      "412: reward_mean=-10374.1, reward_bound=-4218.4, round_mean=31.9,     distance_mean=84.0, steps=1004 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 13:00:55 2018\n",
      "413: reward_mean=-8664.5, reward_bound=-4031.5, round_mean=32.3,     distance_mean=84.5, steps=925 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 13:01:23 2018\n",
      "414: reward_mean=-9809.1, reward_bound=-4130.0, round_mean=32.1,     distance_mean=84.5, steps=986 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 13:01:54 2018\n",
      "415: reward_mean=-9267.0, reward_bound=-4011.4, round_mean=31.7,     distance_mean=83.9, steps=944 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 13:02:22 2018\n",
      "416: reward_mean=-9457.7, reward_bound=-4252.7, round_mean=31.9,     distance_mean=84.3, steps=966 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:02:52 2018\n",
      "417: reward_mean=-12407.9, reward_bound=-3784.7, round_mean=31.9,     distance_mean=83.7, steps=1037 \n",
      "------ \n",
      "iter time: 32 s, localtime: Wed Nov 21 13:03:25 2018\n",
      "418: reward_mean=-9550.2, reward_bound=-4136.8, round_mean=31.4,     distance_mean=83.7, steps=965 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 13:03:55 2018\n",
      "419: reward_mean=-8373.1, reward_bound=-4020.8, round_mean=31.9,     distance_mean=84.4, steps=910 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 13:04:24 2018\n",
      "420: reward_mean=-9475.1, reward_bound=-3992.7, round_mean=31.9,     distance_mean=84.3, steps=953 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:04:53 2018\n",
      "421: reward_mean=-10385.4, reward_bound=-4033.5, round_mean=32.1,     distance_mean=84.3, steps=1003 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 13:05:25 2018\n",
      "422: reward_mean=-10110.4, reward_bound=-4341.5, round_mean=32.2,     distance_mean=84.4, steps=994 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 13:05:56 2018\n",
      "423: reward_mean=-9318.4, reward_bound=-4029.7, round_mean=31.8,     distance_mean=84.1, steps=955 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:06:26 2018\n",
      "424: reward_mean=-10269.4, reward_bound=-3809.7, round_mean=31.7,     distance_mean=83.9, steps=996 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 13:06:57 2018\n",
      "425: reward_mean=-10315.2, reward_bound=-4082.0, round_mean=32.0,     distance_mean=84.4, steps=982 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 13:07:28 2018\n",
      "426: reward_mean=-9933.0, reward_bound=-3955.1, round_mean=31.9,     distance_mean=84.0, steps=971 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:07:58 2018\n",
      "427: reward_mean=-9344.2, reward_bound=-3697.2, round_mean=31.8,     distance_mean=84.1, steps=955 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:08:28 2018\n",
      "428: reward_mean=-9349.0, reward_bound=-4109.5, round_mean=31.7,     distance_mean=83.4, steps=964 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:08:57 2018\n",
      "429: reward_mean=-9779.8, reward_bound=-3987.2, round_mean=31.8,     distance_mean=84.0, steps=970 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:09:27 2018\n",
      "430: reward_mean=-9017.4, reward_bound=-4010.0, round_mean=31.9,     distance_mean=84.1, steps=939 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:09:56 2018\n",
      "431: reward_mean=-10099.7, reward_bound=-4058.1, round_mean=31.6,     distance_mean=83.9, steps=985 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:10:26 2018\n",
      "432: reward_mean=-9161.6, reward_bound=-3879.1, round_mean=31.6,     distance_mean=84.1, steps=948 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:10:55 2018\n",
      "433: reward_mean=-9958.7, reward_bound=-3705.5, round_mean=32.2,     distance_mean=84.5, steps=987 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 13:11:26 2018\n",
      "434: reward_mean=-9404.3, reward_bound=-4081.8, round_mean=31.6,     distance_mean=83.5, steps=961 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:11:55 2018\n",
      "435: reward_mean=-10691.6, reward_bound=-3906.9, round_mean=31.3,     distance_mean=83.1, steps=1011 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 13:12:27 2018\n",
      "436: reward_mean=-10277.4, reward_bound=-4424.5, round_mean=32.2,     distance_mean=84.8, steps=1007 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 13:12:58 2018\n",
      "437: reward_mean=-8707.4, reward_bound=-3863.1, round_mean=31.3,     distance_mean=84.0, steps=926 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 13:13:26 2018\n",
      "438: reward_mean=-8995.6, reward_bound=-3975.3, round_mean=31.8,     distance_mean=83.9, steps=949 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:13:56 2018\n",
      "439: reward_mean=-8981.3, reward_bound=-4163.4, round_mean=31.7,     distance_mean=84.0, steps=946 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 13:14:25 2018\n",
      "440: reward_mean=-10316.6, reward_bound=-4242.2, round_mean=31.4,     distance_mean=84.0, steps=982 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 13:14:56 2018\n",
      "441: reward_mean=-9881.7, reward_bound=-4271.6, round_mean=31.2,     distance_mean=83.8, steps=966 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:15:26 2018\n",
      "442: reward_mean=-8799.9, reward_bound=-3931.8, round_mean=31.3,     distance_mean=83.7, steps=927 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:15:55 2018\n",
      "443: reward_mean=-8626.1, reward_bound=-4006.4, round_mean=32.0,     distance_mean=84.7, steps=927 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:16:24 2018\n",
      "444: reward_mean=-9707.0, reward_bound=-4207.3, round_mean=31.8,     distance_mean=83.8, steps=972 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:16:54 2018\n",
      "445: reward_mean=-9486.9, reward_bound=-4163.5, round_mean=31.4,     distance_mean=84.1, steps=969 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:17:24 2018\n",
      "446: reward_mean=-9896.1, reward_bound=-3701.5, round_mean=31.5,     distance_mean=84.1, steps=965 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 13:17:54 2018\n",
      "447: reward_mean=-9780.6, reward_bound=-4264.8, round_mean=31.7,     distance_mean=83.9, steps=977 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 13:18:24 2018\n",
      "448: reward_mean=-9154.9, reward_bound=-3684.8, round_mean=31.6,     distance_mean=83.9, steps=948 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:18:54 2018\n",
      "449: reward_mean=-10190.6, reward_bound=-4098.0, round_mean=31.4,     distance_mean=83.5, steps=988 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 13:19:25 2018\n",
      "450: reward_mean=-9994.3, reward_bound=-3889.4, round_mean=31.5,     distance_mean=84.0, steps=988 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 13:19:56 2018\n",
      "451: reward_mean=-9778.1, reward_bound=-4159.9, round_mean=31.9,     distance_mean=83.8, steps=987 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 13:20:27 2018\n",
      "452: reward_mean=-9937.7, reward_bound=-3785.8, round_mean=31.5,     distance_mean=84.1, steps=981 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 13:20:57 2018\n",
      "453: reward_mean=-9285.3, reward_bound=-3896.8, round_mean=31.8,     distance_mean=84.1, steps=946 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 13:21:28 2018\n",
      "454: reward_mean=-10217.5, reward_bound=-4109.7, round_mean=31.6,     distance_mean=84.0, steps=1004 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 13:21:59 2018\n",
      "455: reward_mean=-9359.4, reward_bound=-4088.2, round_mean=32.0,     distance_mean=84.2, steps=959 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 13:22:29 2018\n",
      "456: reward_mean=-11182.5, reward_bound=-4407.8, round_mean=31.8,     distance_mean=84.0, steps=1026 \n",
      "------ \n",
      "iter time: 33 s, localtime: Wed Nov 21 13:23:03 2018\n",
      "457: reward_mean=-10612.0, reward_bound=-4110.6, round_mean=32.4,     distance_mean=84.4, steps=999 \n",
      "------ \n",
      "iter time: 32 s, localtime: Wed Nov 21 13:23:35 2018\n",
      "458: reward_mean=-9886.6, reward_bound=-3807.8, round_mean=32.1,     distance_mean=84.0, steps=976 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 13:24:05 2018\n",
      "459: reward_mean=-8636.5, reward_bound=-3834.5, round_mean=31.7,     distance_mean=84.0, steps=910 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 13:24:33 2018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460: reward_mean=-9822.2, reward_bound=-3680.0, round_mean=32.0,     distance_mean=84.5, steps=982 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 13:25:03 2018\n",
      "461: reward_mean=-9130.6, reward_bound=-4059.2, round_mean=32.0,     distance_mean=84.6, steps=946 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 13:25:32 2018\n",
      "462: reward_mean=-11401.3, reward_bound=-3698.6, round_mean=31.8,     distance_mean=83.8, steps=992 \n",
      "------ \n",
      "iter time: 32 s, localtime: Wed Nov 21 13:26:04 2018\n",
      "463: reward_mean=-9436.2, reward_bound=-3845.4, round_mean=32.5,     distance_mean=85.1, steps=966 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 13:26:35 2018\n",
      "464: reward_mean=-9432.5, reward_bound=-4084.9, round_mean=31.6,     distance_mean=83.9, steps=966 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:27:05 2018\n",
      "465: reward_mean=-9178.7, reward_bound=-4067.9, round_mean=31.6,     distance_mean=83.9, steps=948 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 13:27:34 2018\n",
      "466: reward_mean=-9722.1, reward_bound=-4204.1, round_mean=31.4,     distance_mean=83.6, steps=958 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 13:28:04 2018\n",
      "467: reward_mean=-9262.7, reward_bound=-3818.1, round_mean=31.9,     distance_mean=83.9, steps=941 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:28:33 2018\n",
      "468: reward_mean=-9158.3, reward_bound=-3808.8, round_mean=31.5,     distance_mean=83.8, steps=951 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:29:03 2018\n",
      "469: reward_mean=-10856.6, reward_bound=-4209.8, round_mean=31.6,     distance_mean=84.2, steps=996 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 13:29:34 2018\n",
      "470: reward_mean=-10765.3, reward_bound=-3785.7, round_mean=31.6,     distance_mean=83.5, steps=993 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 13:30:05 2018\n",
      "471: reward_mean=-10124.9, reward_bound=-3951.5, round_mean=32.0,     distance_mean=84.2, steps=993 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 13:30:36 2018\n",
      "472: reward_mean=-10605.6, reward_bound=-4005.2, round_mean=32.2,     distance_mean=84.7, steps=1002 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 13:31:07 2018\n",
      "473: reward_mean=-9665.4, reward_bound=-3899.3, round_mean=31.9,     distance_mean=84.0, steps=960 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:31:37 2018\n",
      "474: reward_mean=-9976.4, reward_bound=-3852.6, round_mean=32.1,     distance_mean=84.3, steps=986 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 13:32:09 2018\n",
      "475: reward_mean=-8921.8, reward_bound=-4155.6, round_mean=32.5,     distance_mean=84.8, steps=945 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 13:32:37 2018\n",
      "476: reward_mean=-9965.9, reward_bound=-3679.1, round_mean=31.9,     distance_mean=83.8, steps=983 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 13:33:08 2018\n",
      "477: reward_mean=-9146.5, reward_bound=-3974.4, round_mean=32.2,     distance_mean=84.8, steps=951 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:33:37 2018\n",
      "478: reward_mean=-9068.5, reward_bound=-3775.6, round_mean=31.2,     distance_mean=83.5, steps=942 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 13:34:06 2018\n",
      "479: reward_mean=-10552.8, reward_bound=-3708.5, round_mean=31.6,     distance_mean=84.0, steps=1000 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 13:34:38 2018\n",
      "480: reward_mean=-9825.6, reward_bound=-4014.7, round_mean=31.8,     distance_mean=84.2, steps=987 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 13:35:09 2018\n",
      "481: reward_mean=-9100.2, reward_bound=-4159.4, round_mean=31.8,     distance_mean=83.9, steps=955 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 13:35:38 2018\n",
      "482: reward_mean=-10721.1, reward_bound=-4486.4, round_mean=32.3,     distance_mean=84.6, steps=1014 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 13:36:09 2018\n",
      "483: reward_mean=-9434.6, reward_bound=-3876.2, round_mean=31.1,     distance_mean=83.8, steps=955 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 13:36:37 2018\n",
      "484: reward_mean=-10730.0, reward_bound=-3765.1, round_mean=31.4,     distance_mean=83.8, steps=1009 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 13:37:09 2018\n",
      "485: reward_mean=-8545.1, reward_bound=-4115.0, round_mean=32.2,     distance_mean=84.1, steps=927 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 13:37:38 2018\n",
      "486: reward_mean=-10409.5, reward_bound=-4069.3, round_mean=31.9,     distance_mean=83.9, steps=1004 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 13:38:08 2018\n",
      "487: reward_mean=-9278.9, reward_bound=-3676.6, round_mean=31.7,     distance_mean=84.0, steps=947 \n",
      "------ \n",
      "iter time: 28 s, localtime: Wed Nov 21 13:38:37 2018\n",
      "488: reward_mean=-8844.3, reward_bound=-3993.2, round_mean=31.7,     distance_mean=83.9, steps=938 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:39:06 2018\n",
      "489: reward_mean=-9723.5, reward_bound=-3836.8, round_mean=32.1,     distance_mean=84.2, steps=981 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 13:39:37 2018\n",
      "490: reward_mean=-9312.0, reward_bound=-3979.8, round_mean=31.3,     distance_mean=83.6, steps=954 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:40:06 2018\n",
      "491: reward_mean=-10471.8, reward_bound=-4139.4, round_mean=31.6,     distance_mean=84.1, steps=994 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 13:40:37 2018\n",
      "492: reward_mean=-9184.1, reward_bound=-3973.5, round_mean=32.2,     distance_mean=84.3, steps=949 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:41:07 2018\n",
      "493: reward_mean=-10151.9, reward_bound=-4073.0, round_mean=32.3,     distance_mean=84.4, steps=993 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 13:41:37 2018\n",
      "494: reward_mean=-10466.2, reward_bound=-3779.1, round_mean=32.2,     distance_mean=84.6, steps=989 \n",
      "------ \n",
      "iter time: 31 s, localtime: Wed Nov 21 13:42:08 2018\n",
      "495: reward_mean=-9257.3, reward_bound=-4043.3, round_mean=31.6,     distance_mean=84.0, steps=954 \n",
      "------ \n",
      "iter time: 30 s, localtime: Wed Nov 21 13:42:38 2018\n",
      "496: reward_mean=-10742.5, reward_bound=-4403.3, round_mean=32.0,     distance_mean=84.2, steps=1021 \n",
      "------ \n",
      "iter time: 32 s, localtime: Wed Nov 21 13:43:11 2018\n",
      "497: reward_mean=-9741.3, reward_bound=-3868.8, round_mean=32.0,     distance_mean=84.2, steps=975 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:43:41 2018\n",
      "498: reward_mean=-11353.7, reward_bound=-4211.0, round_mean=31.7,     distance_mean=84.3, steps=1026 \n",
      "------ \n",
      "iter time: 33 s, localtime: Wed Nov 21 13:44:14 2018\n",
      "499: reward_mean=-9511.5, reward_bound=-3878.7, round_mean=31.9,     distance_mean=83.8, steps=950 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:44:43 2018\n",
      "500: reward_mean=-10875.1, reward_bound=-4052.9, round_mean=32.2,     distance_mean=84.5, steps=1006 \n",
      "------ \n",
      "iter time: 32 s, localtime: Wed Nov 21 13:45:15 2018\n",
      "501: reward_mean=-9984.5, reward_bound=-4041.9, round_mean=32.0,     distance_mean=84.5, steps=995 \n",
      "------ \n",
      "iter time: 29 s, localtime: Wed Nov 21 13:45:45 2018\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8321d279a955>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtotal_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mapply_async_with_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUSE_CORES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mreward_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-0313bb701344>\u001b[0m in \u001b[0;36mapply_async_with_callback\u001b[0;34m(pool, core_num, env, net, batch_size)\u001b[0m\n\u001b[1;32m     46\u001b[0m                          callback=collect_results))\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mcore_thrd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    writer = SummaryWriter(comment=\"-test\")\n",
    "    \n",
    "    # net.load_state_dict(torch.load('net_params_init.pkl'))\n",
    "    net.load_state_dict(torch.load('net_params.pkl'))\n",
    "    optimizer = optim.Adam(params=net.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    print(\"start training!!!\")\n",
    "    start = time.time()\n",
    "    \n",
    "    res_batch = []\n",
    "    iter_no = 0\n",
    "    while True:\n",
    "        total_batch = []\n",
    "        apply_async_with_callback(pool, USE_CORES, env, net, BATCH_SIZE)\n",
    "        \n",
    "        reward_mean = float(np.mean(list(map(lambda s: s.reward, total_batch))))\n",
    "        res_batch, obs, acts, reward_b, reward_m, info_m = filter_batch(res_batch + total_batch, PERCENTILE)\n",
    "        if not res_batch:\n",
    "            continue\n",
    "        \n",
    "        iter_no += 1\n",
    "        \n",
    "        localtime = time.asctime( time.localtime(time.time()) )\n",
    "        print(\"%d: reward_mean=%.1f, reward_bound=%.1f, round_mean=%.1f, \\\n",
    "        distance_mean=%.1f, steps=%d \"% \\\n",
    "              (iter_no,  reward_m, reward_b, info_m[1], info_m[2], info_m[3]))\n",
    "        \n",
    "        \n",
    "        obs_v = torch.FloatTensor(obs).cuda()\n",
    "        acts_v = torch.LongTensor(acts).cuda()\n",
    "        res_batch = res_batch[-32:]\n",
    "\n",
    "        for i in range(REUSE_TIMES):\n",
    "            optimizer.zero_grad()\n",
    "            action_scores_v = net(obs_v)\n",
    "            loss_v = objective(action_scores_v, acts_v)\n",
    "            loss_v.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            print(\"-\", end='')\n",
    "        print(\" \")\n",
    "        if iter_no%10 == 0:\n",
    "            torch.save(net.state_dict(), 'net_params.pkl')   \n",
    "            \n",
    "        end = time.time()\n",
    "        print(\"iter time: %d s, localtime:\"% (int(end - start)), localtime)\n",
    "        start = end    \n",
    "        \n",
    "        writer.add_scalar(\"loss\", loss_v.item(), iter_no)\n",
    "        writer.add_scalar(\"reward_bound\", reward_b, iter_no)\n",
    "        writer.add_scalar(\"reward_mean\", reward_m, iter_no)\n",
    "        writer.add_scalar(\"round_mean\", info_m[1], iter_no)\n",
    "        writer.add_scalar(\"distance_mean\", info_m[2], iter_no)\n",
    "        writer.add_scalar(\"step_mean\", info_m[3], iter_no)\n",
    "        # if reward_m > 500:\n",
    "        #     print(\"Solved!\")\n",
    "        #     break\n",
    "        \n",
    "        del loss_v, acts_v, obs_v, action_scores_v, info_m, reward_m\n",
    "        torch.cuda.empty_cache()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    optimizer = optim.Adam(params=net.parameters(), lr=0.001)\n",
    "    \n",
    "    for batch in get_init_batch(env, 32):\n",
    "        batch, obs, acts, reward_b, reward_m, info_m = filter_batch(batch, 30)\n",
    "\n",
    "        obs_v = torch.FloatTensor(obs).cuda()\n",
    "        acts_v = torch.LongTensor(acts).cuda()\n",
    "\n",
    "        for i in range(5):\n",
    "            optimizer.zero_grad()\n",
    "            action_scores_v = net(obs_v)\n",
    "            loss_v = objective(action_scores_v, acts_v)\n",
    "            loss_v.backward()\n",
    "            optimizer.step()\n",
    "            print(\"-\", end='')\n",
    "        print(\" \")\n",
    "            \n",
    "        print(\"reward_mean=%.1f, reward_bound=%.1f, round_mean=%.1f, \\\n",
    "        distance_mean=%.1f, steps=%d \"% \\\n",
    "          (reward_m, reward_b, info_m[1], info_m[2], info_m[3]))\n",
    "        del loss_v, acts_v, obs_v, action_scores_v, info_m, reward_m\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    torch.save(net.state_dict(), 'net_params_init.pkl')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
