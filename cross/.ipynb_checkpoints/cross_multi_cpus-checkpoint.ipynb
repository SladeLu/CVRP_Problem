{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import multiprocessing as mp\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "\n",
    "from test_env import TestEnv_v2\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "PERCENTILE = 50\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "USE_CORES = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, obs_size, hidden_size, n_actions):\n",
    "        super(Net, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_size[1], hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, int(hidden_size/2)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.out = nn.Linear(obs_size[0] * int(hidden_size/2), n_actions) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = x.view(x.size(0), -1)   # to (batch_size, obs_size[0] * hidden_size/2)\n",
    "        output = self.out(x)\n",
    "        return output\n",
    "\n",
    "Episode = namedtuple('Episode', field_names=['reward', 'steps', 'info'])\n",
    "EpisodeStep = namedtuple('EpisodeStep', field_names=['observation', 'action'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_batches(env_input, net, batch_size):\n",
    "    env = copy.deepcopy(env_input)\n",
    "    np.random.seed()\n",
    "    batch = []\n",
    "    episode_reward = 0.0\n",
    "    episode_steps = []\n",
    "    obs = env.reset()\n",
    "    sm = nn.Softmax(dim=1)\n",
    "    while True:\n",
    "        obs_v = torch.FloatTensor([obs]).cuda()\n",
    "        act_probs_v = sm(net(obs_v))\n",
    "        act_probs = act_probs_v.cpu().data.numpy()[0]\n",
    "        action = np.random.choice(len(act_probs), p=act_probs)\n",
    "        next_obs, reward, is_done, ext_info = env.step(action)\n",
    "        episode_reward += reward\n",
    "        episode_steps.append(EpisodeStep(observation=obs, action=action))\n",
    "        if is_done or ext_info[3] > 5000:\n",
    "            batch.append(Episode(reward=episode_reward, steps=episode_steps, info=ext_info))\n",
    "            print(\"round_mean=%.1f, distance_mean=%.1f, steps=%d \"% \\\n",
    "              (ext_info[1], ext_info[2], ext_info[3]))\n",
    "            episode_reward = 0.0\n",
    "            episode_steps = []\n",
    "            next_obs = env.reset()\n",
    "            if len(batch) == batch_size:\n",
    "                del env, episode_steps, obs, obs_v, act_probs_v, act_probs, next_obs, ext_info\n",
    "                return batch\n",
    "        obs = next_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_batch(batch, percentile):\n",
    "    rewards = list(map(lambda s: s.reward, batch))\n",
    "    infos = np.array(list(map(lambda s: s.info, batch)))\n",
    "    reward_bound = np.percentile(rewards, percentile)\n",
    "    reward_mean = float(np.mean(rewards))\n",
    "    info_mean = np.mean(infos,axis=0)\n",
    "\n",
    "    train_obs = []\n",
    "    train_act = []\n",
    "    for example in batch:\n",
    "        if example.reward < reward_bound:\n",
    "            continue\n",
    "        train_obs.extend(map(lambda step: step.observation, example.steps))\n",
    "        train_act.extend(map(lambda step: step.action, example.steps))\n",
    "\n",
    "    train_obs_v = torch.FloatTensor(train_obs).cuda()\n",
    "    train_act_v = torch.LongTensor(train_act).cuda()\n",
    "    return train_obs_v, train_act_v, reward_bound, reward_mean, info_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_init_batch(env_input,batch_size):\n",
    "    env = copy.deepcopy(env_input)\n",
    "    batch = []\n",
    "    episode_reward = 0.0\n",
    "    episode_steps = []\n",
    "    obs = env.reset()\n",
    "    r = 0\n",
    "    test_num = 0\n",
    "    while True:\n",
    "        r = random.randint(0,99)\n",
    "        next_obs, reward, is_done,  ext_info = env.step(r)\n",
    "        episode_reward += reward\n",
    "        test_num +=1\n",
    "        episode_steps.append(EpisodeStep(observation=obs, action=r))\n",
    "        if is_done:\n",
    "            batch.append(Episode(reward=episode_reward, steps=episode_steps, info=ext_info))\n",
    "            episode_reward = 0.0\n",
    "            episode_steps = []\n",
    "            next_obs = env.reset()\n",
    "            if len(batch) == batch_size:\n",
    "                del env, episode_steps, obs, next_obs, ext_info\n",
    "                return batch\n",
    "                break;\n",
    "        obs = next_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 4 GPUs!\n",
      "round_mean=21.0, distance_mean=71.1, steps=3794 \n",
      "round_mean=21.0, distance_mean=71.1, steps=3794 \n",
      "round_mean=21.0, distance_mean=71.1, steps=3794 \n",
      "round_mean=21.0, distance_mean=71.1, steps=3794 \n",
      "round_mean=21.0, distance_mean=71.1, steps=3794 \n",
      "round_mean=21.0, distance_mean=71.1, steps=3794 \n",
      "round_mean=21.0, distance_mean=71.1, steps=3794 \n",
      "round_mean=21.0, distance_mean=71.1, steps=3794 \n",
      "round_mean=21.0, distance_mean=71.1, steps=3794 \n",
      "round_mean=21.0, distance_mean=71.1, steps=3794 \n",
      "round_mean=21.0, distance_mean=71.1, steps=3794 \n",
      "round_mean=21.0, distance_mean=71.1, steps=3794 \n",
      "round_mean=21.0, distance_mean=72.3, steps=3644 \n",
      "round_mean=21.0, distance_mean=72.3, steps=3644 \n",
      "round_mean=21.0, distance_mean=72.3, steps=3644 \n",
      "round_mean=21.0, distance_mean=72.3, steps=3644 \n",
      "round_mean=21.0, distance_mean=72.3, steps=3644 \n",
      "round_mean=21.0, distance_mean=72.3, steps=3644 \n",
      "round_mean=21.0, distance_mean=72.3, steps=3644 \n",
      "round_mean=21.0, distance_mean=72.3, steps=3644 \n",
      "round_mean=21.0, distance_mean=72.3, steps=3644 \n",
      "round_mean=21.0, distance_mean=72.3, steps=3644 \n",
      "round_mean=21.0, distance_mean=72.3, steps=3644 \n",
      "round_mean=21.0, distance_mean=72.3, steps=3644 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-12:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-11:\n",
      "Process ForkPoolWorker-10:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-9:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-4-eefc1afe598d>\", line 13, in produce_batches\n",
      "    next_obs, reward, is_done, ext_info = env.step(action)\n",
      "  File \"<ipython-input-4-eefc1afe598d>\", line 10, in produce_batches\n",
      "    act_probs_v = sm(net(obs_v))\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-4-eefc1afe598d>\", line 10, in produce_batches\n",
      "    act_probs_v = sm(net(obs_v))\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-4-eefc1afe598d>\", line 12, in produce_batches\n",
      "    action = np.random.choice(len(act_probs), p=act_probs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-4-eefc1afe598d>\", line 13, in produce_batches\n",
      "    next_obs, reward, is_done, ext_info = env.step(action)\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 138, in step\n",
      "    self._go_next_point(action)\n",
      "  File \"<ipython-input-4-eefc1afe598d>\", line 13, in produce_batches\n",
      "    next_obs, reward, is_done, ext_info = env.step(action)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-4-eefc1afe598d>\", line 13, in produce_batches\n",
      "    next_obs, reward, is_done, ext_info = env.step(action)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-4-eefc1afe598d>\", line 9, in produce_batches\n",
      "    obs_v = torch.FloatTensor([obs]).cuda()\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-4-eefc1afe598d>\", line 13, in produce_batches\n",
      "    next_obs, reward, is_done, ext_info = env.step(action)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-4-eefc1afe598d>\", line 10, in produce_batches\n",
      "    act_probs_v = sm(net(obs_v))\n",
      "  File \"<ipython-input-4-eefc1afe598d>\", line 10, in produce_batches\n",
      "    act_probs_v = sm(net(obs_v))\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 138, in step\n",
      "    self._go_next_point(action)\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 213, in _go_next_point\n",
      "    self._get_state()\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 129, in step\n",
      "    self._reset_round()\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 129, in step\n",
      "    self._reset_round()\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 114, in forward\n",
      "    outputs = self.parallel_apply(replicas, inputs, kwargs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 115, in forward\n",
      "    return self.gather(outputs, self.output_device)\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 138, in step\n",
      "    self._go_next_point(action)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 213, in _go_next_point\n",
      "    self._get_state()\n",
      "  File \"<ipython-input-4-eefc1afe598d>\", line 10, in produce_batches\n",
      "    act_probs_v = sm(net(obs_v))\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 177, in _reset_round\n",
      "    self._get_state()\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 230, in _get_state\n",
      "    self.state[i][j] = self.point_state[i].state()[j]\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 177, in _reset_round\n",
      "    self._get_state()\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 124, in parallel_apply\n",
      "    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 127, in gather\n",
      "    return gather(outputs, output_device, dim=self.dim)\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 213, in _go_next_point\n",
      "    self._get_state()\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 114, in forward\n",
      "    outputs = self.parallel_apply(replicas, inputs, kwargs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 113, in forward\n",
      "    replicas = self.replicate(self.module, self.device_ids[:len(inputs)])\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 230, in _get_state\n",
      "    self.state[i][j] = self.point_state[i].state()[j]\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 230, in _get_state\n",
      "    self.state[i][j] = self.point_state[i].state()[j]\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 50, in state\n",
      "    return np.array(state)\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 230, in _get_state\n",
      "    self.state[i][j] = self.point_state[i].state()[j]\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 230, in _get_state\n",
      "    self.state[i][j] = self.point_state[i].state()[j]\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\", line 59, in parallel_apply\n",
      "    _worker(0, modules[0], inputs[0], kwargs_tup[0], devices[0])\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\", line 68, in gather\n",
      "    return gather_map(outputs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 124, in parallel_apply\n",
      "    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 49, in state\n",
      "    state = (self.x, self.y, self.weight, self.is_current)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 118, in replicate\n",
      "    return replicate(module, device_ids)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 110, in forward\n",
      "    inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids)\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 50, in state\n",
      "    return np.array(state)\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 50, in state\n",
      "    return np.array(state)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddli/delivery/test_env.py\", line 50, in state\n",
      "    return np.array(state)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\", line 59, in parallel_apply\n",
      "    _worker(0, modules[0], inputs[0], kwargs_tup[0], devices[0])\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\", line 55, in gather_map\n",
      "    return Gather.apply(target_device, dim, *outputs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\", line 121, in scatter\n",
      "    return scatter_kwargs(inputs, kwargs, device_ids, dim=self.dim)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\", line 36, in _worker\n",
      "    torch.set_grad_enabled(grad_enabled)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/replicate.py\", line 32, in replicate\n",
      "    replica._modules = replica._modules.copy()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\", line 41, in _worker\n",
      "    output = module(*input, **kwargs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/_functions.py\", line 55, in forward\n",
      "    return comm.gather(inputs, ctx.dim, ctx.target_device)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\", line 36, in scatter_kwargs\n",
      "    inputs = scatter(inputs, target_gpus, dim) if inputs else []\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 534, in __setattr__\n",
      "    def __setattr__(self, name, value):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/cuda/comm.py\", line 195, in gather\n",
      "    result = tensors[0].new(expected_size, device=destination)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\", line 29, in scatter\n",
      "    return scatter_map(inputs)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-3-94f578790d8f>\", line 13, in forward\n",
      "    x = self.net(x)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\", line 16, in scatter_map\n",
      "    return list(zip(*map(scatter_map, obj)))\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py\", line 14, in scatter_map\n",
      "    return Scatter.apply(target_gpus, None, dim, obj)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/modules/container.py\", line 91, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/parallel/_functions.py\", line 74, in forward\n",
      "    outputs = comm.scatter(input, ctx.target_gpus, ctx.chunk_sizes, ctx.dim, streams)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/cuda/comm.py\", line 157, in scatter\n",
      "    with torch.cuda.device(device), torch.cuda.stream(stream):\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 55, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/cuda/__init__.py\", line 222, in __enter__\n",
      "    def __enter__(self):\n",
      "  File \"/home/ddli/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/nn/functional.py\", line 994, in linear\n",
      "    output = input.matmul(weight.t())\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    env = TestEnv_v2()\n",
    "    # env = gym.wrappers.Monitor(env, directory=\"mon\", force=True)\n",
    "    # os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "    \n",
    "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # print(device_lib.list_local_devices())\n",
    "    \n",
    "    # pool.close()\n",
    "    \n",
    "    pool = mp.Pool(processes = USE_CORES)\n",
    "    \n",
    "    obs_size = env.observation_size\n",
    "    n_actions = env.action_num\n",
    "\n",
    "    net = Net(obs_size, HIDDEN_SIZE, n_actions)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    net = nn.DataParallel(net)\n",
    "\n",
    "    net = net.cuda()\n",
    "    \n",
    "    objective = nn.CrossEntropyLoss().cuda()\n",
    "    optimizer = optim.Adam(params=net.parameters(), lr=LEARNING_RATE)\n",
    "    writer = SummaryWriter(comment=\"-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test round:0\n",
      "loss=6.283, reward_mean=295.5, reward_bound=266.9, round_mean=30.5, distance_mean=84.6\n",
      "test round:1\n",
      "loss=4.669, reward_mean=322.9, reward_bound=288.9, round_mean=28.7, distance_mean=80.7\n",
      "test round:2\n",
      "loss=4.607, reward_mean=325.9, reward_bound=291.4, round_mean=29.1, distance_mean=80.3\n",
      "test round:3\n",
      "loss=4.605, reward_mean=324.6, reward_bound=279.3, round_mean=30.5, distance_mean=83.5\n",
      "test round:4\n",
      "loss=4.605, reward_mean=322.9, reward_bound=275.5, round_mean=30.1, distance_mean=82.7\n"
     ]
    }
   ],
   "source": [
    "    optimizer = optim.Adam(params=net.parameters(), lr=0.0005)\n",
    "    for t in range(3):\n",
    "        print(\"test round:%d\"% (t))\n",
    "        multi_res = []\n",
    "        for i in range(USE_CORES):\n",
    "            multi_res.append(pool.apply_async(get_init_batch, (env,BATCH_SIZE)))\n",
    "\n",
    "        for i in range(USE_CORES):\n",
    "            batch = multi_res[i].get()  \n",
    "            obs_v, acts_v, reward_b, reward_m, info_m = filter_batch(batch, 10)\n",
    "            optimizer.zero_grad()\n",
    "            action_scores_v = net(obs_v)\n",
    "            loss_v = objective(action_scores_v, acts_v)\n",
    "            loss_v.backward()\n",
    "            optimizer.step()\n",
    "            # writer.add_scalar(\"loss\", loss_v.item())\n",
    "            # writer.add_scalar(\"reward_bound\", reward_b)\n",
    "            # writer.add_scalar(\"reward_mean\", reward_m)\n",
    "            \n",
    "        print(\"loss=%.3f, reward_mean=%.1f, reward_bound=%.1f, round_mean=%.1f, distance_mean=%.1f\" % (\n",
    "                        loss_v.item(), reward_m, reward_b, info_m[1], info_m[2]))\n",
    "\n",
    "    torch.save(net.state_dict(), 'net_params_init.pkl')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0b420f536cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUSE_CORES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mobs_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macts_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPERCENTILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    optimizer = optim.Adam(params=net.parameters(), lr=LEARNING_RATE)\n",
    "    print(\"start train!\")\n",
    "    writer = SummaryWriter(comment=\"-test\")\n",
    "    iter_no = 0\n",
    "    train_no = 0\n",
    "    t0 = time.time()\n",
    "    # net.load_state_dict(torch.load('net_params_init.pkl'))\n",
    "    net.load_state_dict(torch.load('net_params.pkl'))\n",
    "    while True:\n",
    "        multi_res = []\n",
    "        \n",
    "        for i in range(USE_CORES):\n",
    "            multi_res.append(pool.apply_async(produce_batches, (env, net, BATCH_SIZE)))\n",
    "        \n",
    "        # pool.close()\n",
    "        # pool.join()\n",
    "            \n",
    "        for i in range(USE_CORES):\n",
    "            batch = multi_res[i].get()   \n",
    "            \n",
    "            obs_v, acts_v, reward_b, reward_m, info_m = filter_batch(batch, PERCENTILE)\n",
    "            optimizer.zero_grad()\n",
    "            action_scores_v = net(obs_v)\n",
    "            loss_v = objective(action_scores_v, acts_v)\n",
    "            loss_v.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_no = iter_no * USE_CORES + i\n",
    "            if iter_no%5 == 0:\n",
    "                torch.save(net.state_dict(), 'net_params.pkl')   \n",
    "            print(\"%d: loss=%.3f, reward_mean=%.1f, reward_bound=%.1f, round_mean=%.1f, distance_mean=%.1f\" % (\n",
    "                train_no, loss_v.item(), reward_m, reward_b, info_m[1], info_m[2]))\n",
    "            writer.add_scalar(\"loss\", loss_v.item(), train_no)\n",
    "            writer.add_scalar(\"reward_bound\", reward_b, train_no)\n",
    "            writer.add_scalar(\"reward_mean\", reward_m, train_no)\n",
    "            writer.add_scalar(\"round_mean\", info_m[1], train_no)\n",
    "            writer.add_scalar(\"distance_mean\", info_m[2], train_no)\n",
    "            \n",
    "            if reward_m > 500:\n",
    "                print(\"Solved!\")\n",
    "                break\n",
    "        iter_no += 1      \n",
    "        t1 = time.time()\n",
    "        localtime = time.asctime( time.localtime(time.time()) )\n",
    "        print(\"iter time: %d s, localtime: \"% (int(t1 - t0)), localtime)\n",
    "        t0 = t1\n",
    "        del loss_v, acts_v, obs_v, action_scores_v, info_m, multi_res, reward_m\n",
    "        torch.cuda.empty_cache()\n",
    "            \n",
    "    writer.close()\n",
    "    pool.close()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
